{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN , Gated Recurrent Unit to build a model using a pre trained Word Embeddings Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srita\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_input_file = \"glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_output_file = \"word2vec.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove2word2vec(glove_input_file,word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of loaded word vectors:  400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.array(values[1:],dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "print(\"Len of loaded word vectors: \",len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[\"woman\",\"king\"],negative=['man'],topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Quora Questions dataset and Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quora_duplicate_questions.tsv\",delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['id','qid1','qid2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "\n",
    "stops = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']\n",
    "# punct = list(string.punctuation)\n",
    "# punct.append(\"''\")\n",
    "# punct.append(\":\")\n",
    "# punct.append(\"...\")\n",
    "# punct.append(\"@\")\n",
    "# punct.append('\"\"')\n",
    "def cleanData(text, lowercase = False, punct = False, remove_stops = False, stemming = False, lemmatization = False):\n",
    "    txt = str(text)\n",
    "    \n",
    "    # Replace apostrophes with standard lexicons\n",
    "    txt = txt.replace(\"isn't\", \"is not\")\n",
    "    txt = txt.replace(\"aren't\", \"are not\")\n",
    "    txt = txt.replace(\"ain't\", \"am not\")\n",
    "    txt = txt.replace(\"won't\", \"will not\")\n",
    "    txt = txt.replace(\"didn't\", \"did not\")\n",
    "    txt = txt.replace(\"shan't\", \"shall not\")\n",
    "    txt = txt.replace(\"haven't\", \"have not\")\n",
    "    txt = txt.replace(\"hadn't\", \"had not\")\n",
    "    txt = txt.replace(\"hasn't\", \"has not\")\n",
    "    txt = txt.replace(\"don't\", \"do not\")\n",
    "    txt = txt.replace(\"wasn't\", \"was not\")\n",
    "    txt = txt.replace(\"weren't\", \"were not\")\n",
    "    txt = txt.replace(\"doesn't\", \"does not\")\n",
    "    txt = txt.replace(\"gotta\",\"got to\")\n",
    "    txt = txt.replace(\"quikly\",\"quickly\")\n",
    "    txt = txt.replace(\"'s\", \" is\")\n",
    "    txt = txt.replace(\"'re\", \" are\")\n",
    "    txt = txt.replace(\"'m\", \" am\")\n",
    "    txt = txt.replace(\"'d\", \" would\")\n",
    "    txt = txt.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # More cleaning\n",
    "    txt = re.sub(r\"review\", \"\", txt)\n",
    "    txt = re.sub(r\"Review\", \"\", txt)\n",
    "    txt = re.sub(r\"TripAdvisor\", \"\", txt)\n",
    "    txt = re.sub(r\"reviews\", \"\", txt)\n",
    "    txt = re.sub(r\"Hotel\", \"\", txt)\n",
    "    txt = re.sub(r\"what's\", \"\", txt)\n",
    "    txt = re.sub(r\"What's\", \"\", txt)\n",
    "    txt = re.sub(r\"\\'s\", \" \", txt)\n",
    "    txt = txt.replace(\"pic\", \"picture\")\n",
    "    txt = re.sub(r\"\\'ve\", \" have \", txt)\n",
    "    txt = re.sub(r\"can't\", \"cannot \", txt)\n",
    "    txt = re.sub(r\"n't\", \" not \", txt)\n",
    "    txt = re.sub(r\"I'm\", \"I am\", txt)\n",
    "    txt = re.sub(r\" m \", \" am \", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are \", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would \", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will \", txt)\n",
    "    txt = re.sub(r\"60k\", \" 60000 \", txt)\n",
    "    txt = re.sub(r\" e g \", \" eg \", txt)\n",
    "    txt = re.sub(r\" b g \", \" bg \", txt)\n",
    "    txt = re.sub(r\"\\0s\", \"0\", txt)\n",
    "    txt = re.sub(r\" 9 11 \", \"911\", txt)\n",
    "    txt = re.sub(r\"e-mail\", \"email\", txt)\n",
    "    txt = re.sub(r\"\\s{2,}\", \" \", txt)\n",
    "    txt = re.sub(r\"quikly\", \"quickly\", txt)\n",
    "    txt = re.sub(r\" usa \", \" America \", txt)\n",
    "    txt = re.sub(r\" USA \", \" America \", txt)\n",
    "    txt = re.sub(r\" u s \", \" America \", txt)\n",
    "    txt = re.sub(r\" uk \", \" England \", txt)\n",
    "    txt = re.sub(r\" UK \", \" England \", txt)\n",
    "    txt = re.sub(r\"india\", \"India\", txt)\n",
    "    txt = re.sub(r\"switzerland\", \"Switzerland\", txt)\n",
    "    txt = re.sub(r\"china\", \"China\", txt)\n",
    "    txt = re.sub(r\"chinese\", \"Chinese\", txt) \n",
    "    txt = re.sub(r\"imrovement\", \"improvement\", txt)\n",
    "    txt = re.sub(r\"intially\", \"initially\", txt)\n",
    "    txt = re.sub(r\"quora\", \"Quora\", txt)\n",
    "    txt = re.sub(r\" dms \", \"direct messages \", txt)  \n",
    "    txt = re.sub(r\"demonitization\", \"demonetization\", txt) \n",
    "    txt = re.sub(r\"actived\", \"active\", txt)\n",
    "    txt = re.sub(r\"kms\", \" kilometers \", txt)\n",
    "    txt = re.sub(r\"KMs\", \" kilometers \", txt)\n",
    "    txt = re.sub(r\" cs \", \" computer science \", txt) \n",
    "    txt = re.sub(r\" upvotes \", \" up votes \", txt)\n",
    "    txt = re.sub(r\" iPhone \", \" phone \", txt)\n",
    "    txt = re.sub(r\"\\0rs \", \" rs \", txt) \n",
    "    txt = re.sub(r\"calender\", \"calendar\", txt)\n",
    "    txt = re.sub(r\"ios\", \"operating system\", txt)\n",
    "    txt = re.sub(r\"gps\", \"GPS\", txt)\n",
    "    txt = re.sub(r\"gst\", \"GST\", txt)\n",
    "    txt = re.sub(r\"programing\", \"programming\", txt)\n",
    "    txt = re.sub(r\"bestfriend\", \"best friend\", txt)\n",
    "    txt = re.sub(r\"dna\", \"DNA\", txt)\n",
    "    txt = re.sub(r\"III\", \"3\", txt) \n",
    "    txt = re.sub(r\"the US\", \"America\", txt)\n",
    "    txt = re.sub(r\"Astrology\", \"astrology\", txt)\n",
    "    txt = re.sub(r\"Method\", \"method\", txt)\n",
    "    txt = re.sub(r\"Find\", \"find\", txt) \n",
    "    txt = re.sub(r\"banglore\", \"Banglore\", txt)\n",
    "    txt = re.sub(r\" J K \", \" JK \", txt)\n",
    "\n",
    "    # Emoji replacement\n",
    "    txt = re.sub(r':\\)',r' Happy ',txt)\n",
    "    txt = re.sub(r':D',r' Happy ',txt)\n",
    "    txt = re.sub(r':P',r' Happy ',txt)\n",
    "    txt = re.sub(r':\\(',r' Sad ',txt)\n",
    "    \n",
    "    # Remove urls and emails\n",
    "    txt = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', txt, flags=re.MULTILINE)\n",
    "    txt = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', txt, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    if punct:\n",
    "        txt = \"\".join([c for c in text if c not in punctuation])\n",
    "\n",
    "   \n",
    "       \n",
    "    # Replace words like sooooooo with so\n",
    "    txt = \"\".join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "    \n",
    "    # Split attached words\n",
    "    #txt = \" \".join(re.findall('[A-Z][^A-Z]*', txt))   \n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "#         print (len(txt.split()))\n",
    "#         print (txt)\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(lambda x: cleanData(x, lowercase = True, punct = False, remove_stops = False, stemming = True, lemmatization = True))\n",
    "df['question2'] = df['question2'].apply(lambda x: cleanData(x,lowercase = True, punct = False, remove_stops = False, stemming = True, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what be the step by step guid to invest in sha...</td>\n",
       "      <td>what be the step by step guid to invest in sha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what be the stori of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>what would happen if the indian govern steal t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increas the speed of my internet con...</td>\n",
       "      <td>how can internet speed be increas by hack thro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whi be i mental veri lonely? how can i solv it?</td>\n",
       "      <td>find the remaind when [math]23^{24}[/math] be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolv in water quickli sugar, salt...</td>\n",
       "      <td>which fish would surviv in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what be the step by step guid to invest in sha...   \n",
       "1  what be the stori of kohinoor (koh-i-noor) dia...   \n",
       "2  how can i increas the speed of my internet con...   \n",
       "3    whi be i mental veri lonely? how can i solv it?   \n",
       "4  which one dissolv in water quickli sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what be the step by step guid to invest in sha...             0  \n",
       "1  what would happen if the indian govern steal t...             0  \n",
       "2  how can internet speed be increas by hack thro...             0  \n",
       "3  find the remaind when [math]23^{24}[/math] be ...             0  \n",
       "4             which fish would surviv in salt water?             0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and creating embedding matrix for question1 and question2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot,text_to_word_sequence,Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text = np.hstack([df.question1, df.question2])\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(raw_text)\n",
    "df['q1_encoded'] = t.texts_to_sequences(df.question1)\n",
    "df['q2_encoded'] = t.texts_to_sequences(df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90150\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(t.word_index) + 1\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89745\n"
     ]
    }
   ],
   "source": [
    "MAX_TEXT = np.max([np.max(df.q1_encoded.max()),np.max(df.q2_encoded.max())]) + 2\n",
    "print(MAX_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_encoded</th>\n",
       "      <th>q2_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what be the step by step guid to invest in sha...</td>\n",
       "      <td>what be the step by step guid to invest in sha...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 1, 2, 651, 57, 651, 2211, 7, 299, 8, 545, ...</td>\n",
       "      <td>[3, 1, 2, 651, 57, 651, 2211, 7, 299, 8, 545, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what be the stori of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>what would happen if the indian govern steal t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 1, 2, 588, 10, 12708, 12030, 4, 19292, 3430]</td>\n",
       "      <td>[3, 44, 97, 25, 2, 80, 257, 2336, 2, 12708, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increas the speed of my internet con...</td>\n",
       "      <td>how can internet speed be increas by hack thro...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 12, 4, 198, 2, 441, 10, 17, 373, 597, 203,...</td>\n",
       "      <td>[5, 12, 373, 441, 1, 198, 57, 303, 230, 17389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whi be i mental veri lonely? how can i solv it?</td>\n",
       "      <td>find the remaind when [math]23^{24}[/math] be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 1, 4, 1129, 325, 3815, 5, 12, 4, 535, 15]</td>\n",
       "      <td>[75, 2, 3781, 38, 216, 2078, 1296, 216, 1, 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolv in water quickli sugar, salt...</td>\n",
       "      <td>which fish would surviv in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[24, 49, 5188, 8, 241, 1847, 1757, 1849, 13075...</td>\n",
       "      <td>[24, 1580, 44, 1149, 8, 1849, 241]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what be the step by step guid to invest in sha...   \n",
       "1  what be the stori of kohinoor (koh-i-noor) dia...   \n",
       "2  how can i increas the speed of my internet con...   \n",
       "3    whi be i mental veri lonely? how can i solv it?   \n",
       "4  which one dissolv in water quickli sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  what be the step by step guid to invest in sha...             0   \n",
       "1  what would happen if the indian govern steal t...             0   \n",
       "2  how can internet speed be increas by hack thro...             0   \n",
       "3  find the remaind when [math]23^{24}[/math] be ...             0   \n",
       "4             which fish would surviv in salt water?             0   \n",
       "\n",
       "                                          q1_encoded  \\\n",
       "0  [3, 1, 2, 651, 57, 651, 2211, 7, 299, 8, 545, ...   \n",
       "1   [3, 1, 2, 588, 10, 12708, 12030, 4, 19292, 3430]   \n",
       "2  [5, 12, 4, 198, 2, 441, 10, 17, 373, 597, 203,...   \n",
       "3     [16, 1, 4, 1129, 325, 3815, 5, 12, 4, 535, 15]   \n",
       "4  [24, 49, 5188, 8, 241, 1847, 1757, 1849, 13075...   \n",
       "\n",
       "                                          q2_encoded  \n",
       "0  [3, 1, 2, 651, 57, 651, 2211, 7, 299, 8, 545, ...  \n",
       "1  [3, 44, 97, 25, 2, 80, 257, 2336, 2, 12708, 12...  \n",
       "2     [5, 12, 373, 441, 1, 198, 57, 303, 230, 17389]  \n",
       "3  [75, 2, 3781, 38, 216, 2078, 1296, 216, 1, 172...  \n",
       "4                 [24, 1580, 44, 1149, 8, 1849, 241]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_size = 32\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'q1': pad_sequences(dataset.q1_encoded, maxlen=50),\n",
    "        'q2': pad_sequences(dataset.q2_encoded, maxlen=50)\n",
    "        \n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_embedding_matrix = np.zeros((vocabulary_size,100))\n",
    "#embedding_index contains words from glove\n",
    "for word,i in t.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        q1_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating embedding_matrix for q2\n",
    "q2_embedding_matrix = np.zeros((vocabulary_size,100))\n",
    "#embedding_index contains words from glove\n",
    "for word,i in t.word_index.items():\n",
    "    q2_embedding_vector = embedding_index.get(word)\n",
    "    if q2_embedding_vector is not None:\n",
    "        q2_embedding_matrix[i] = q2_embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303217, 5)\n",
      "(101073, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(df, random_state=123, train_size=0.75)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "dropout_r = 0.1\n",
    "adam = Adam(lr=0.001)\n",
    "q1 = Input(shape=[X_train[\"q1\"].shape[1]], name=\"q1\", dtype='int32')\n",
    "q2 = Input(shape=[X_train[\"q2\"].shape[1]], name=\"q2\", dtype='int32')\n",
    "\n",
    "emb_q1 = Embedding(vocabulary_size,100,weights=[q1_embedding_matrix],input_length=32,trainable=False)(q1)\n",
    "emb_q2 = Embedding(vocabulary_size,100,weights=[q2_embedding_matrix],input_length=32,trainable=False)(q2)\n",
    "rnn_layer1 = GRU(16) (emb_q1)\n",
    "rnn_layer2 = GRU(16) (emb_q2)\n",
    "main_l = concatenate([rnn_layer1, rnn_layer2])\n",
    "main_l = Dropout(dropout_r) (Dense(128) (main_l))\n",
    "main_l = Dropout(dropout_r) (Dense(64) (main_l))\n",
    "output = Dense(1, activation=\"sigmoid\") (main_l)\n",
    "model_GRU = Model([q1,q2],output)\n",
    "model_GRU.compile(loss='binary_crossentropy',optimizer=adam, metrics=['acc'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "q1 (InputLayer)                 (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q2 (InputLayer)                 (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 32, 100)      9015000     q1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 32, 100)      9015000     q2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 16)           5616        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 16)           5616        embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32)           0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          4224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 18,053,777\n",
      "Trainable params: 23,777\n",
      "Non-trainable params: 18,030,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303217 samples, validate on 101073 samples\n",
      "Epoch 1/5\n",
      "303217/303217 [==============================] - 225s 743us/step - loss: 0.6748 - acc: 0.6052 - val_loss: 0.6534 - val_acc: 0.6301\n",
      "Epoch 2/5\n",
      "303217/303217 [==============================] - 211s 696us/step - loss: 0.6510 - acc: 0.6342 - val_loss: 0.6426 - val_acc: 0.6421\n",
      "Epoch 3/5\n",
      "303217/303217 [==============================] - 204s 674us/step - loss: 0.6396 - acc: 0.6450 - val_loss: 0.6320 - val_acc: 0.6542\n",
      "Epoch 4/5\n",
      "303217/303217 [==============================] - 196s 645us/step - loss: 0.6291 - acc: 0.6560 - val_loss: 0.6217 - val_acc: 0.6649\n",
      "Epoch 5/5\n",
      "303217/303217 [==============================] - 207s 684us/step - loss: 0.6180 - acc: 0.6659 - val_loss: 0.6117 - val_acc: 0.6735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2a85254a8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 20000\n",
    "epochs = 5\n",
    "\n",
    "model_GRU.fit(X_train, y_train, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, y_)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "val_preds = model_GRU.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds_x_train = model_GRU.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_final = get_keras_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final_preds = model_GRU.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final_classes = np.argmax(y_final_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['predictions_probs'] = y_final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_score(row):\n",
    "    row['results'] = 1 if row['predictions_probs'] > 0.5 else 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['results'] = df['predictions_probs'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_encoded</th>\n",
       "      <th>q2_encoded</th>\n",
       "      <th>predictions_probs</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>astrology: i be a capricorn sun cap moon and c...</td>\n",
       "      <td>i be a tripl capricorn (sun, moon and ascend i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3309, 4, 1, 6, 8211, 876, 3441, 766, 11, 3441...</td>\n",
       "      <td>[4, 1, 6, 4425, 8211, 876, 766, 11, 8941, 8, 8...</td>\n",
       "      <td>0.150777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how can i be a good geologist?</td>\n",
       "      <td>what should i do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 12, 4, 1, 6, 42, 18330]</td>\n",
       "      <td>[3, 29, 4, 9, 7, 1, 6, 352, 18330]</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what wa your first sexual experi like?</td>\n",
       "      <td>what wa your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 58, 33, 102, 1017, 361, 36]</td>\n",
       "      <td>[3, 58, 33, 102, 1017, 881]</td>\n",
       "      <td>0.423808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what would a trump presid mean for current int...</td>\n",
       "      <td>how will a trump presid affect the student pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 44, 6, 91, 284, 72, 13, 329, 382, 7608, 15...</td>\n",
       "      <td>[5, 34, 6, 91, 284, 259, 2, 151, 854, 8, 199, ...</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>what doe manipul mean?</td>\n",
       "      <td>what doe manipul means?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 20, 3721, 72]</td>\n",
       "      <td>[3, 20, 3721, 2987]</td>\n",
       "      <td>0.306189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>whi do rocket look white?</td>\n",
       "      <td>whi be rocket and booster paint white?</td>\n",
       "      <td>1</td>\n",
       "      <td>[16, 9, 3545, 152, 348]</td>\n",
       "      <td>[16, 1, 3545, 11, 8246, 1195, 348]</td>\n",
       "      <td>0.312528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>what be some special care for someon with a no...</td>\n",
       "      <td>how can i keep my nose from get stuffi at night?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 794, 610, 13, 86, 28, 6, 1797, 27, ...</td>\n",
       "      <td>[5, 12, 4, 296, 17, 1797, 32, 22, 11486, 41, 614]</td>\n",
       "      <td>0.318407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>what game of throne villain would be the most ...</td>\n",
       "      <td>what game of throne villain would you most lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 187, 10, 1704, 4175, 44, 1, 2, 52, 36, 7, ...</td>\n",
       "      <td>[3, 187, 10, 1704, 4175, 44, 14, 52, 36, 7, 1,...</td>\n",
       "      <td>0.309191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>how do we prepar for upsc?</td>\n",
       "      <td>how do i prepar for civil service?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 9, 53, 133, 13, 992]</td>\n",
       "      <td>[5, 9, 4, 133, 13, 443, 1536]</td>\n",
       "      <td>0.442758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>what be some exampl of product that can be mak...</td>\n",
       "      <td>what be some of the product make from crude oil?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 233, 10, 261, 27, 12, 1, 37, 32, 60...</td>\n",
       "      <td>[3, 1, 26, 10, 2, 261, 37, 32, 6072, 704]</td>\n",
       "      <td>0.246882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>how do i make friends.</td>\n",
       "      <td>how to make friend ?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 9, 4, 37, 762]</td>\n",
       "      <td>[5, 7, 37, 173]</td>\n",
       "      <td>0.485807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>be career launcher good for rbi grade b prepar...</td>\n",
       "      <td>how be career launcher onlin program for rbi g...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 272, 8844, 42, 13, 1416, 976, 276, 1457]</td>\n",
       "      <td>[5, 1, 272, 8844, 165, 148, 13, 1416, 976, 276]</td>\n",
       "      <td>0.221655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>will a blu ray play on a regular dvd player? i...</td>\n",
       "      <td>how can you play a blu ray dvd on a regular dv...</td>\n",
       "      <td>1</td>\n",
       "      <td>[34, 6, 6240, 2456, 220, 19, 6, 1527, 3613, 87...</td>\n",
       "      <td>[5, 12, 14, 220, 6, 6240, 2456, 3613, 19, 6, 1...</td>\n",
       "      <td>0.130023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>i wa suddenli log off gmail. i cannot rememb m...</td>\n",
       "      <td>i cannot rememb my gmail password or my recove...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 58, 1776, 1061, 308, 408, 4, 225, 1043, 17...</td>\n",
       "      <td>[4, 225, 1043, 17, 408, 305, 23, 17, 1251, 304...</td>\n",
       "      <td>0.452363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>how be the new harri potter book 'harri potter...</td>\n",
       "      <td>how bad be the new book by j.k rowling?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 1, 2, 77, 1064, 1224, 89, 18331, 1224, 11,...</td>\n",
       "      <td>[5, 213, 1, 2, 77, 89, 57, 1603, 1367, 23530]</td>\n",
       "      <td>0.322616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>what be java programming? how to learn java pr...</td>\n",
       "      <td>how do i learn a comput languag like java?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 362, 658, 5, 7, 56, 362, 148, 207]</td>\n",
       "      <td>[5, 9, 4, 56, 6, 219, 207, 36, 362]</td>\n",
       "      <td>0.405138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>can we ever store energi produc in lightning?</td>\n",
       "      <td>be it possibl to store the energi of lightning?</td>\n",
       "      <td>1</td>\n",
       "      <td>[12, 53, 94, 591, 336, 1065, 8, 7786]</td>\n",
       "      <td>[1, 15, 130, 7, 591, 2, 336, 10, 7786]</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>how help be quickbooks' auto data recoveri sup...</td>\n",
       "      <td>what be the quickbook custom support phone num...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 159, 1, 23570, 2282, 209, 1251, 267, 87, 1...</td>\n",
       "      <td>[3, 1, 2, 1592, 779, 267, 87, 129, 928]</td>\n",
       "      <td>0.182329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>who be the richest gambler of all time and how...</td>\n",
       "      <td>who be the richest gambler of all time and how...</td>\n",
       "      <td>1</td>\n",
       "      <td>[39, 1, 2, 2515, 9758, 10, 85, 61, 11, 5, 12, ...</td>\n",
       "      <td>[39, 1, 2, 2515, 9758, 10, 85, 61, 11, 5, 12, ...</td>\n",
       "      <td>0.249108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>what be purpos of life?</td>\n",
       "      <td>what be the purpos of life? what be life actua...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 487, 10, 64]</td>\n",
       "      <td>[3, 1, 2, 487, 10, 64, 3, 1, 64, 350, 50]</td>\n",
       "      <td>0.441449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>what be some of the high salari incom job in t...</td>\n",
       "      <td>what be some high pay job for a fresher with a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 10, 2, 250, 439, 1021, 96, 8, 2, 57...</td>\n",
       "      <td>[3, 1, 26, 250, 244, 96, 13, 6, 1114, 28, 31, ...</td>\n",
       "      <td>0.320645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>how can i increas my height after 21 also?</td>\n",
       "      <td>can height increas after 25?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 12, 4, 198, 17, 485, 66, 1451, 539]</td>\n",
       "      <td>[12, 485, 198, 66, 1156]</td>\n",
       "      <td>0.454770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>what be the major effect of the cambodia earth...</td>\n",
       "      <td>what be the major effect of the cambodia earth...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 2, 178, 167, 10, 2, 1481, 1525, 11, 5, ...</td>\n",
       "      <td>[3, 1, 2, 178, 167, 10, 2, 1481, 1525, 11, 5, ...</td>\n",
       "      <td>0.256639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>which be the best game laptop under 600 inr?</td>\n",
       "      <td>which be the best game laptop under rs 600?</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 1, 2, 18, 187, 253, 190, 1554, 804]</td>\n",
       "      <td>[24, 1, 2, 18, 187, 253, 190, 205, 1554]</td>\n",
       "      <td>0.499397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>what be some of the best romant movi in english?</td>\n",
       "      <td>what be the best romant movi you have ever seen?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 10, 2, 18, 1439, 132, 8, 112]</td>\n",
       "      <td>[3, 1, 2, 18, 1439, 132, 14, 21, 94, 1244]</td>\n",
       "      <td>0.481593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>how doe 3d print work?</td>\n",
       "      <td>how do 3d print work?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 20, 1433, 1120, 67]</td>\n",
       "      <td>[5, 9, 1433, 1120, 67]</td>\n",
       "      <td>0.211248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>will there realli be ani war between india and...</td>\n",
       "      <td>will there be a nuclear war between india and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[34, 46, 135, 1, 59, 154, 51, 35, 11, 312, 185...</td>\n",
       "      <td>[34, 46, 1, 6, 921, 154, 51, 35, 11, 312]</td>\n",
       "      <td>0.381219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>what be the differ between love and pity?</td>\n",
       "      <td>what be the differ between love and pity?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 2, 47, 51, 107, 11, 18332]</td>\n",
       "      <td>[3, 1, 2, 47, 51, 107, 11, 18332]</td>\n",
       "      <td>0.285939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>whi my question wa mark as need improvement?</td>\n",
       "      <td>how can i ask a question without get mark as â€˜...</td>\n",
       "      <td>1</td>\n",
       "      <td>[16, 17, 82, 58, 328, 48, 113, 798]</td>\n",
       "      <td>[5, 12, 4, 125, 6, 82, 98, 22, 328, 48, 23804,...</td>\n",
       "      <td>0.444799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>what miner hold the highest electr charge?</td>\n",
       "      <td>what miner can hold the greatest electr charge?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 4675, 960, 2, 1176, 468, 3512]</td>\n",
       "      <td>[3, 4675, 12, 960, 2, 896, 468, 3512]</td>\n",
       "      <td>0.346347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404155</th>\n",
       "      <td>what make tata group chairman cyru mistri to q...</td>\n",
       "      <td>whi cyru mistri ha be remov from tata group?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 37, 1215, 515, 2875, 1616, 1786, 7, 937]</td>\n",
       "      <td>[16, 1616, 1786, 69, 1, 383, 32, 1215, 515]</td>\n",
       "      <td>0.335657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404162</th>\n",
       "      <td>what be the option for a chemic engin after b....</td>\n",
       "      <td>what be the career opportun after finish chemi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 2, 378, 13, 6, 707, 131, 66, 276, 346]</td>\n",
       "      <td>[3, 1, 2, 272, 1075, 66, 1774, 707, 340]</td>\n",
       "      <td>0.334735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404168</th>\n",
       "      <td>what be some good site for learn python?</td>\n",
       "      <td>what be the best learn site for python?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 42, 262, 13, 56, 530]</td>\n",
       "      <td>[3, 1, 2, 18, 56, 262, 13, 530]</td>\n",
       "      <td>0.479963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404170</th>\n",
       "      <td>how do you start a hedg fund?</td>\n",
       "      <td>how can i start a hedg fund after college?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 9, 14, 79, 6, 3014, 657]</td>\n",
       "      <td>[5, 12, 4, 79, 6, 3014, 657, 66, 659]</td>\n",
       "      <td>0.415583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404174</th>\n",
       "      <td>be kapil sharma married?</td>\n",
       "      <td>ha kapil sharma realli married?</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4116, 3387, 1828]</td>\n",
       "      <td>[69, 4116, 3387, 135, 1828]</td>\n",
       "      <td>0.351595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404176</th>\n",
       "      <td>be there ani other clegan in westeros?</td>\n",
       "      <td>be there ani other clegan in the world?</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 46, 59, 95, 19448, 8, 10365]</td>\n",
       "      <td>[1, 46, 59, 95, 19448, 8, 2, 99]</td>\n",
       "      <td>0.284220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404183</th>\n",
       "      <td>which fruit contain fat?</td>\n",
       "      <td>what fruit contain fat?</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 1860, 1444, 402]</td>\n",
       "      <td>[3, 1860, 1444, 402]</td>\n",
       "      <td>0.303560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404191</th>\n",
       "      <td>do you have an imaginari friend? what be your ...</td>\n",
       "      <td>do you have ani imaginari friends?</td>\n",
       "      <td>1</td>\n",
       "      <td>[9, 14, 21, 31, 6025, 173, 3, 1, 33, 1421]</td>\n",
       "      <td>[9, 14, 21, 59, 6025, 762]</td>\n",
       "      <td>0.406355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404200</th>\n",
       "      <td>what be some cv worthi onlin digit market cour...</td>\n",
       "      <td>digit market colleg in india?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 26, 2905, 5482, 165, 385, 217, 2090]</td>\n",
       "      <td>[385, 217, 208, 8, 35]</td>\n",
       "      <td>0.499261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404206</th>\n",
       "      <td>ha anybodi run the meep softwar on a window pl...</td>\n",
       "      <td>how do i instal and use meep softwar on a wind...</td>\n",
       "      <td>1</td>\n",
       "      <td>[69, 1767, 318, 2, 24303, 271, 19, 6, 400, 1134]</td>\n",
       "      <td>[5, 9, 4, 407, 11, 40, 24303, 271, 19, 6, 400,...</td>\n",
       "      <td>0.288064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404208</th>\n",
       "      <td>what wa the main caus of world war one?</td>\n",
       "      <td>what be the real reason for world war one?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 58, 2, 412, 218, 10, 99, 154, 49]</td>\n",
       "      <td>[3, 1, 2, 186, 266, 13, 99, 154, 49]</td>\n",
       "      <td>0.498193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404215</th>\n",
       "      <td>what be it like to work with aaron sorkin?</td>\n",
       "      <td>what be it like to work with aaron sorkin?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 15, 36, 7, 67, 28, 9613, 28433]</td>\n",
       "      <td>[3, 1, 15, 36, 7, 67, 28, 9613, 28433]</td>\n",
       "      <td>0.443878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404221</th>\n",
       "      <td>will intern colleg student be neg affect if tr...</td>\n",
       "      <td>will the trump factor affect the admiss of int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[34, 382, 208, 151, 1, 887, 259, 25, 91, 83, 421]</td>\n",
       "      <td>[34, 2, 91, 970, 259, 2, 833, 10, 382, 151, 8,...</td>\n",
       "      <td>0.485414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404227</th>\n",
       "      <td>how doe russian polit affect australia and new...</td>\n",
       "      <td>how do russian polit and geostrategi affect au...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 20, 1336, 553, 259, 629, 11, 77, 2476]</td>\n",
       "      <td>[5, 9, 1336, 553, 11, 90145, 259, 629, 11, 77,...</td>\n",
       "      <td>0.475697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404231</th>\n",
       "      <td>be klopp overrated?</td>\n",
       "      <td>be jurgen klopp an overr manager?</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 24830, 2826]</td>\n",
       "      <td>[1, 24829, 24830, 31, 2771, 2249]</td>\n",
       "      <td>0.222703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404241</th>\n",
       "      <td>how can i get into a good college?</td>\n",
       "      <td>how do i get into a realli good college?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 12, 4, 22, 114, 6, 42, 659]</td>\n",
       "      <td>[5, 9, 4, 22, 114, 6, 135, 42, 659]</td>\n",
       "      <td>0.492422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404243</th>\n",
       "      <td>how doe quora determin how mani view an answer...</td>\n",
       "      <td>how be the number of view on quora counted?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 20, 54, 724, 5, 84, 247, 31, 157, 13608]</td>\n",
       "      <td>[5, 1, 2, 129, 10, 247, 19, 54, 9066]</td>\n",
       "      <td>0.473112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404247</th>\n",
       "      <td>among bollywood stars, which actor or actress ...</td>\n",
       "      <td>who be some bollywood actor and actress who be...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1090, 643, 4082, 24, 797, 23, 1396, 20, 354, ...</td>\n",
       "      <td>[39, 1, 26, 643, 797, 11, 1396, 39, 1, 62, 13,...</td>\n",
       "      <td>0.244062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404249</th>\n",
       "      <td>should i stop use pornographi as a masturbator...</td>\n",
       "      <td>should i perman let go of look at, view or wat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[29, 4, 145, 40, 5966, 48, 6, 14651, 3037]</td>\n",
       "      <td>[29, 4, 1034, 736, 71, 10, 152, 41, 247, 23, 2...</td>\n",
       "      <td>0.234508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404257</th>\n",
       "      <td>what be bitcoin? be it legal in india?</td>\n",
       "      <td>be bitcoin legal in india?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 1915, 1, 15, 437, 8, 35]</td>\n",
       "      <td>[1, 1915, 437, 8, 35]</td>\n",
       "      <td>0.444365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404258</th>\n",
       "      <td>what be the differ between a psychologist and ...</td>\n",
       "      <td>what be the differ between psychologist and ps...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 2, 47, 51, 6, 3949, 11, 6, 4389, 4164]</td>\n",
       "      <td>[3, 1, 2, 47, 51, 3949, 11, 32701]</td>\n",
       "      <td>0.287759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404259</th>\n",
       "      <td>what do you think be wrong with indian school ...</td>\n",
       "      <td>what be wrong with the current indian education?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 9, 14, 70, 1, 476, 28, 80, 183, 11, 1550]</td>\n",
       "      <td>[3, 1, 476, 28, 2, 329, 80, 1550]</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404261</th>\n",
       "      <td>who be the overal most popular game of throne ...</td>\n",
       "      <td>who be the most popular charact in the game of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[39, 1, 2, 3215, 52, 463, 187, 10, 1704, 2487]</td>\n",
       "      <td>[39, 1, 2, 52, 463, 867, 8, 2, 187, 10, 1704, ...</td>\n",
       "      <td>0.281430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404267</th>\n",
       "      <td>what be the caus of the fall of the roman empire?</td>\n",
       "      <td>what be the most import caus and effect of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 1, 2, 218, 10, 2, 423, 10, 2, 2054, 3041]</td>\n",
       "      <td>[3, 1, 2, 52, 166, 218, 11, 167, 10, 2, 423, 1...</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404273</th>\n",
       "      <td>what happen if you put milk in a coffe maker?</td>\n",
       "      <td>what would happen if i put milk instead of wat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 97, 25, 14, 577, 1181, 8, 6, 1467, 4219]</td>\n",
       "      <td>[3, 44, 97, 25, 4, 577, 1181, 489, 10, 241, 8,...</td>\n",
       "      <td>0.309480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404274</th>\n",
       "      <td>will the next gener of parent chang or stay th...</td>\n",
       "      <td>what kind of parent will the next gener have?</td>\n",
       "      <td>1</td>\n",
       "      <td>[34, 2, 365, 339, 10, 483, 146, 23, 444, 2, 231]</td>\n",
       "      <td>[3, 391, 10, 483, 34, 2, 365, 339, 21]</td>\n",
       "      <td>0.267053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404281</th>\n",
       "      <td>whi be manaphi childish in pokÃ©mon ranger and ...</td>\n",
       "      <td>whi be manaphi annoy in pokemon ranger and the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[16, 1, 2416, 11184, 8, 1002, 2562, 11, 2, 190...</td>\n",
       "      <td>[16, 1, 2416, 2169, 8, 1569, 2562, 11, 2, 1903...</td>\n",
       "      <td>0.214212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404282</th>\n",
       "      <td>how doe a long distanc relationship work?</td>\n",
       "      <td>how be long distanc relationship maintained?</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 20, 6, 141, 708, 285, 67]</td>\n",
       "      <td>[5, 1, 141, 708, 285, 8611]</td>\n",
       "      <td>0.425473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>what doe jainism say about homosexuality?</td>\n",
       "      <td>what doe jainism say about gay and homosexuality?</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 20, 7586, 137, 50, 5666]</td>\n",
       "      <td>[3, 20, 7586, 137, 50, 738, 11, 5666]</td>\n",
       "      <td>0.412323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>do you believ there be life after death?</td>\n",
       "      <td>be it true that there be life after death?</td>\n",
       "      <td>1</td>\n",
       "      <td>[9, 14, 333, 46, 1, 64, 66, 519]</td>\n",
       "      <td>[1, 15, 273, 27, 46, 1, 64, 66, 519]</td>\n",
       "      <td>0.483645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96581 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "5       astrology: i be a capricorn sun cap moon and c...   \n",
       "7                          how can i be a good geologist?   \n",
       "13                 what wa your first sexual experi like?   \n",
       "15      what would a trump presid mean for current int...   \n",
       "16                                 what doe manipul mean?   \n",
       "20                              whi do rocket look white?   \n",
       "31      what be some special care for someon with a no...   \n",
       "32      what game of throne villain would be the most ...   \n",
       "38                             how do we prepar for upsc?   \n",
       "48      what be some exampl of product that can be mak...   \n",
       "49                                 how do i make friends.   \n",
       "50      be career launcher good for rbi grade b prepar...   \n",
       "51      will a blu ray play on a regular dvd player? i...   \n",
       "58      i wa suddenli log off gmail. i cannot rememb m...   \n",
       "62      how be the new harri potter book 'harri potter...   \n",
       "65      what be java programming? how to learn java pr...   \n",
       "67          can we ever store energi produc in lightning?   \n",
       "73      how help be quickbooks' auto data recoveri sup...   \n",
       "74      who be the richest gambler of all time and how...   \n",
       "79                                what be purpos of life?   \n",
       "84      what be some of the high salari incom job in t...   \n",
       "85             how can i increas my height after 21 also?   \n",
       "86      what be the major effect of the cambodia earth...   \n",
       "88           which be the best game laptop under 600 inr?   \n",
       "92       what be some of the best romant movi in english?   \n",
       "95                                 how doe 3d print work?   \n",
       "100     will there realli be ani war between india and...   \n",
       "107             what be the differ between love and pity?   \n",
       "120          whi my question wa mark as need improvement?   \n",
       "122            what miner hold the highest electr charge?   \n",
       "...                                                   ...   \n",
       "404155  what make tata group chairman cyru mistri to q...   \n",
       "404162  what be the option for a chemic engin after b....   \n",
       "404168           what be some good site for learn python?   \n",
       "404170                      how do you start a hedg fund?   \n",
       "404174                           be kapil sharma married?   \n",
       "404176             be there ani other clegan in westeros?   \n",
       "404183                           which fruit contain fat?   \n",
       "404191  do you have an imaginari friend? what be your ...   \n",
       "404200  what be some cv worthi onlin digit market cour...   \n",
       "404206  ha anybodi run the meep softwar on a window pl...   \n",
       "404208            what wa the main caus of world war one?   \n",
       "404215         what be it like to work with aaron sorkin?   \n",
       "404221  will intern colleg student be neg affect if tr...   \n",
       "404227  how doe russian polit affect australia and new...   \n",
       "404231                                be klopp overrated?   \n",
       "404241                 how can i get into a good college?   \n",
       "404243  how doe quora determin how mani view an answer...   \n",
       "404247  among bollywood stars, which actor or actress ...   \n",
       "404249  should i stop use pornographi as a masturbator...   \n",
       "404257             what be bitcoin? be it legal in india?   \n",
       "404258  what be the differ between a psychologist and ...   \n",
       "404259  what do you think be wrong with indian school ...   \n",
       "404261  who be the overal most popular game of throne ...   \n",
       "404267  what be the caus of the fall of the roman empire?   \n",
       "404273      what happen if you put milk in a coffe maker?   \n",
       "404274  will the next gener of parent chang or stay th...   \n",
       "404281  whi be manaphi childish in pokÃ©mon ranger and ...   \n",
       "404282          how doe a long distanc relationship work?   \n",
       "404284          what doe jainism say about homosexuality?   \n",
       "404286           do you believ there be life after death?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "5       i be a tripl capricorn (sun, moon and ascend i...             1   \n",
       "7               what should i do to be a great geologist?             1   \n",
       "13                  what wa your first sexual experience?             1   \n",
       "15      how will a trump presid affect the student pre...             1   \n",
       "16                                what doe manipul means?             1   \n",
       "20                 whi be rocket and booster paint white?             1   \n",
       "31       how can i keep my nose from get stuffi at night?             1   \n",
       "32      what game of throne villain would you most lik...             1   \n",
       "38                     how do i prepar for civil service?             1   \n",
       "48       what be some of the product make from crude oil?             1   \n",
       "49                                   how to make friend ?             1   \n",
       "50      how be career launcher onlin program for rbi g...             1   \n",
       "51      how can you play a blu ray dvd on a regular dv...             1   \n",
       "58      i cannot rememb my gmail password or my recove...             1   \n",
       "62                how bad be the new book by j.k rowling?             1   \n",
       "65             how do i learn a comput languag like java?             1   \n",
       "67        be it possibl to store the energi of lightning?             1   \n",
       "73      what be the quickbook custom support phone num...             1   \n",
       "74      who be the richest gambler of all time and how...             1   \n",
       "79      what be the purpos of life? what be life actua...             1   \n",
       "84      what be some high pay job for a fresher with a...             1   \n",
       "85                           can height increas after 25?             1   \n",
       "86      what be the major effect of the cambodia earth...             1   \n",
       "88            which be the best game laptop under rs 600?             1   \n",
       "92       what be the best romant movi you have ever seen?             1   \n",
       "95                                  how do 3d print work?             1   \n",
       "100     will there be a nuclear war between india and ...             1   \n",
       "107             what be the differ between love and pity?             1   \n",
       "120     how can i ask a question without get mark as â€˜...             1   \n",
       "122       what miner can hold the greatest electr charge?             1   \n",
       "...                                                   ...           ...   \n",
       "404155       whi cyru mistri ha be remov from tata group?             1   \n",
       "404162  what be the career opportun after finish chemi...             1   \n",
       "404168            what be the best learn site for python?             1   \n",
       "404170         how can i start a hedg fund after college?             1   \n",
       "404174                    ha kapil sharma realli married?             1   \n",
       "404176            be there ani other clegan in the world?             1   \n",
       "404183                            what fruit contain fat?             1   \n",
       "404191                 do you have ani imaginari friends?             1   \n",
       "404200                      digit market colleg in india?             1   \n",
       "404206  how do i instal and use meep softwar on a wind...             1   \n",
       "404208         what be the real reason for world war one?             1   \n",
       "404215         what be it like to work with aaron sorkin?             1   \n",
       "404221  will the trump factor affect the admiss of int...             1   \n",
       "404227  how do russian polit and geostrategi affect au...             1   \n",
       "404231                  be jurgen klopp an overr manager?             1   \n",
       "404241           how do i get into a realli good college?             1   \n",
       "404243        how be the number of view on quora counted?             1   \n",
       "404247  who be some bollywood actor and actress who be...             1   \n",
       "404249  should i perman let go of look at, view or wat...             1   \n",
       "404257                         be bitcoin legal in india?             1   \n",
       "404258  what be the differ between psychologist and ps...             1   \n",
       "404259   what be wrong with the current indian education?             1   \n",
       "404261  who be the most popular charact in the game of...             1   \n",
       "404267  what be the most import caus and effect of the...             1   \n",
       "404273  what would happen if i put milk instead of wat...             1   \n",
       "404274      what kind of parent will the next gener have?             1   \n",
       "404281  whi be manaphi annoy in pokemon ranger and the...             1   \n",
       "404282       how be long distanc relationship maintained?             1   \n",
       "404284  what doe jainism say about gay and homosexuality?             1   \n",
       "404286         be it true that there be life after death?             1   \n",
       "\n",
       "                                               q1_encoded  \\\n",
       "5       [3309, 4, 1, 6, 8211, 876, 3441, 766, 11, 3441...   \n",
       "7                             [5, 12, 4, 1, 6, 42, 18330]   \n",
       "13                        [3, 58, 33, 102, 1017, 361, 36]   \n",
       "15      [3, 44, 6, 91, 284, 72, 13, 329, 382, 7608, 15...   \n",
       "16                                      [3, 20, 3721, 72]   \n",
       "20                                [16, 9, 3545, 152, 348]   \n",
       "31      [3, 1, 26, 794, 610, 13, 86, 28, 6, 1797, 27, ...   \n",
       "32      [3, 187, 10, 1704, 4175, 44, 1, 2, 52, 36, 7, ...   \n",
       "38                               [5, 9, 53, 133, 13, 992]   \n",
       "48      [3, 1, 26, 233, 10, 261, 27, 12, 1, 37, 32, 60...   \n",
       "49                                     [5, 9, 4, 37, 762]   \n",
       "50           [1, 272, 8844, 42, 13, 1416, 976, 276, 1457]   \n",
       "51      [34, 6, 6240, 2456, 220, 19, 6, 1527, 3613, 87...   \n",
       "58      [4, 58, 1776, 1061, 308, 408, 4, 225, 1043, 17...   \n",
       "62      [5, 1, 2, 77, 1064, 1224, 89, 18331, 1224, 11,...   \n",
       "65              [3, 1, 362, 658, 5, 7, 56, 362, 148, 207]   \n",
       "67                  [12, 53, 94, 591, 336, 1065, 8, 7786]   \n",
       "73      [5, 159, 1, 23570, 2282, 209, 1251, 267, 87, 1...   \n",
       "74      [39, 1, 2, 2515, 9758, 10, 85, 61, 11, 5, 12, ...   \n",
       "79                                    [3, 1, 487, 10, 64]   \n",
       "84      [3, 1, 26, 10, 2, 250, 439, 1021, 96, 8, 2, 57...   \n",
       "85                [5, 12, 4, 198, 17, 485, 66, 1451, 539]   \n",
       "86      [3, 1, 2, 178, 167, 10, 2, 1481, 1525, 11, 5, ...   \n",
       "88               [24, 1, 2, 18, 187, 253, 190, 1554, 804]   \n",
       "92               [3, 1, 26, 10, 2, 18, 1439, 132, 8, 112]   \n",
       "95                                [5, 20, 1433, 1120, 67]   \n",
       "100     [34, 46, 135, 1, 59, 154, 51, 35, 11, 312, 185...   \n",
       "107                     [3, 1, 2, 47, 51, 107, 11, 18332]   \n",
       "120                   [16, 17, 82, 58, 328, 48, 113, 798]   \n",
       "122                    [3, 4675, 960, 2, 1176, 468, 3512]   \n",
       "...                                                   ...   \n",
       "404155       [3, 37, 1215, 515, 2875, 1616, 1786, 7, 937]   \n",
       "404162      [3, 1, 2, 378, 13, 6, 707, 131, 66, 276, 346]   \n",
       "404168                   [3, 1, 26, 42, 262, 13, 56, 530]   \n",
       "404170                       [5, 9, 14, 79, 6, 3014, 657]   \n",
       "404174                              [1, 4116, 3387, 1828]   \n",
       "404176                   [1, 46, 59, 95, 19448, 8, 10365]   \n",
       "404183                              [24, 1860, 1444, 402]   \n",
       "404191         [9, 14, 21, 31, 6025, 173, 3, 1, 33, 1421]   \n",
       "404200        [3, 1, 26, 2905, 5482, 165, 385, 217, 2090]   \n",
       "404206   [69, 1767, 318, 2, 24303, 271, 19, 6, 400, 1134]   \n",
       "404208              [3, 58, 2, 412, 218, 10, 99, 154, 49]   \n",
       "404215             [3, 1, 15, 36, 7, 67, 28, 9613, 28433]   \n",
       "404221  [34, 382, 208, 151, 1, 887, 259, 25, 91, 83, 421]   \n",
       "404227         [5, 20, 1336, 553, 259, 629, 11, 77, 2476]   \n",
       "404231                                   [1, 24830, 2826]   \n",
       "404241                    [5, 12, 4, 22, 114, 6, 42, 659]   \n",
       "404243       [5, 20, 54, 724, 5, 84, 247, 31, 157, 13608]   \n",
       "404247  [1090, 643, 4082, 24, 797, 23, 1396, 20, 354, ...   \n",
       "404249         [29, 4, 145, 40, 5966, 48, 6, 14651, 3037]   \n",
       "404257                    [3, 1, 1915, 1, 15, 437, 8, 35]   \n",
       "404258      [3, 1, 2, 47, 51, 6, 3949, 11, 6, 4389, 4164]   \n",
       "404259      [3, 9, 14, 70, 1, 476, 28, 80, 183, 11, 1550]   \n",
       "404261     [39, 1, 2, 3215, 52, 463, 187, 10, 1704, 2487]   \n",
       "404267      [3, 1, 2, 218, 10, 2, 423, 10, 2, 2054, 3041]   \n",
       "404273       [3, 97, 25, 14, 577, 1181, 8, 6, 1467, 4219]   \n",
       "404274   [34, 2, 365, 339, 10, 483, 146, 23, 444, 2, 231]   \n",
       "404281  [16, 1, 2416, 11184, 8, 1002, 2562, 11, 2, 190...   \n",
       "404282                      [5, 20, 6, 141, 708, 285, 67]   \n",
       "404284                       [3, 20, 7586, 137, 50, 5666]   \n",
       "404286                   [9, 14, 333, 46, 1, 64, 66, 519]   \n",
       "\n",
       "                                               q2_encoded  predictions_probs  \\\n",
       "5       [4, 1, 6, 4425, 8211, 876, 766, 11, 8941, 8, 8...           0.150777   \n",
       "7                      [3, 29, 4, 9, 7, 1, 6, 352, 18330]           0.410625   \n",
       "13                            [3, 58, 33, 102, 1017, 881]           0.423808   \n",
       "15      [5, 34, 6, 91, 284, 259, 2, 151, 854, 8, 199, ...           0.144300   \n",
       "16                                    [3, 20, 3721, 2987]           0.306189   \n",
       "20                     [16, 1, 3545, 11, 8246, 1195, 348]           0.312528   \n",
       "31      [5, 12, 4, 296, 17, 1797, 32, 22, 11486, 41, 614]           0.318407   \n",
       "32      [3, 187, 10, 1704, 4175, 44, 14, 52, 36, 7, 1,...           0.309191   \n",
       "38                          [5, 9, 4, 133, 13, 443, 1536]           0.442758   \n",
       "48              [3, 1, 26, 10, 2, 261, 37, 32, 6072, 704]           0.246882   \n",
       "49                                        [5, 7, 37, 173]           0.485807   \n",
       "50        [5, 1, 272, 8844, 165, 148, 13, 1416, 976, 276]           0.221655   \n",
       "51      [5, 12, 14, 220, 6, 6240, 2456, 3613, 19, 6, 1...           0.130023   \n",
       "58      [4, 225, 1043, 17, 408, 305, 23, 17, 1251, 304...           0.452363   \n",
       "62          [5, 213, 1, 2, 77, 89, 57, 1603, 1367, 23530]           0.322616   \n",
       "65                    [5, 9, 4, 56, 6, 219, 207, 36, 362]           0.405138   \n",
       "67                 [1, 15, 130, 7, 591, 2, 336, 10, 7786]           0.205978   \n",
       "73                [3, 1, 2, 1592, 779, 267, 87, 129, 928]           0.182329   \n",
       "74      [39, 1, 2, 2515, 9758, 10, 85, 61, 11, 5, 12, ...           0.249108   \n",
       "79              [3, 1, 2, 487, 10, 64, 3, 1, 64, 350, 50]           0.441449   \n",
       "84      [3, 1, 26, 250, 244, 96, 13, 6, 1114, 28, 31, ...           0.320645   \n",
       "85                               [12, 485, 198, 66, 1156]           0.454770   \n",
       "86      [3, 1, 2, 178, 167, 10, 2, 1481, 1525, 11, 5, ...           0.256639   \n",
       "88               [24, 1, 2, 18, 187, 253, 190, 205, 1554]           0.499397   \n",
       "92             [3, 1, 2, 18, 1439, 132, 14, 21, 94, 1244]           0.481593   \n",
       "95                                 [5, 9, 1433, 1120, 67]           0.211248   \n",
       "100             [34, 46, 1, 6, 921, 154, 51, 35, 11, 312]           0.381219   \n",
       "107                     [3, 1, 2, 47, 51, 107, 11, 18332]           0.285939   \n",
       "120     [5, 12, 4, 125, 6, 82, 98, 22, 328, 48, 23804,...           0.444799   \n",
       "122                 [3, 4675, 12, 960, 2, 896, 468, 3512]           0.346347   \n",
       "...                                                   ...                ...   \n",
       "404155        [16, 1616, 1786, 69, 1, 383, 32, 1215, 515]           0.335657   \n",
       "404162           [3, 1, 2, 272, 1075, 66, 1774, 707, 340]           0.334735   \n",
       "404168                    [3, 1, 2, 18, 56, 262, 13, 530]           0.479963   \n",
       "404170              [5, 12, 4, 79, 6, 3014, 657, 66, 659]           0.415583   \n",
       "404174                        [69, 4116, 3387, 135, 1828]           0.351595   \n",
       "404176                   [1, 46, 59, 95, 19448, 8, 2, 99]           0.284220   \n",
       "404183                               [3, 1860, 1444, 402]           0.303560   \n",
       "404191                         [9, 14, 21, 59, 6025, 762]           0.406355   \n",
       "404200                             [385, 217, 208, 8, 35]           0.499261   \n",
       "404206  [5, 9, 4, 407, 11, 40, 24303, 271, 19, 6, 400,...           0.288064   \n",
       "404208               [3, 1, 2, 186, 266, 13, 99, 154, 49]           0.498193   \n",
       "404215             [3, 1, 15, 36, 7, 67, 28, 9613, 28433]           0.443878   \n",
       "404221  [34, 2, 91, 970, 259, 2, 833, 10, 382, 151, 8,...           0.485414   \n",
       "404227  [5, 9, 1336, 553, 11, 90145, 259, 629, 11, 77,...           0.475697   \n",
       "404231                  [1, 24829, 24830, 31, 2771, 2249]           0.222703   \n",
       "404241                [5, 9, 4, 22, 114, 6, 135, 42, 659]           0.492422   \n",
       "404243              [5, 1, 2, 129, 10, 247, 19, 54, 9066]           0.473112   \n",
       "404247  [39, 1, 26, 643, 797, 11, 1396, 39, 1, 62, 13,...           0.244062   \n",
       "404249  [29, 4, 1034, 736, 71, 10, 152, 41, 247, 23, 2...           0.234508   \n",
       "404257                              [1, 1915, 437, 8, 35]           0.444365   \n",
       "404258                 [3, 1, 2, 47, 51, 3949, 11, 32701]           0.287759   \n",
       "404259                  [3, 1, 476, 28, 2, 329, 80, 1550]           0.423221   \n",
       "404261  [39, 1, 2, 52, 463, 867, 8, 2, 187, 10, 1704, ...           0.281430   \n",
       "404267  [3, 1, 2, 52, 166, 218, 11, 167, 10, 2, 423, 1...           0.313592   \n",
       "404273  [3, 44, 97, 25, 4, 577, 1181, 489, 10, 241, 8,...           0.309480   \n",
       "404274             [3, 391, 10, 483, 34, 2, 365, 339, 21]           0.267053   \n",
       "404281  [16, 1, 2416, 2169, 8, 1569, 2562, 11, 2, 1903...           0.214212   \n",
       "404282                        [5, 1, 141, 708, 285, 8611]           0.425473   \n",
       "404284              [3, 20, 7586, 137, 50, 738, 11, 5666]           0.412323   \n",
       "404286               [1, 15, 273, 27, 46, 1, 64, 66, 519]           0.483645   \n",
       "\n",
       "        results  \n",
       "5             0  \n",
       "7             0  \n",
       "13            0  \n",
       "15            0  \n",
       "16            0  \n",
       "20            0  \n",
       "31            0  \n",
       "32            0  \n",
       "38            0  \n",
       "48            0  \n",
       "49            0  \n",
       "50            0  \n",
       "51            0  \n",
       "58            0  \n",
       "62            0  \n",
       "65            0  \n",
       "67            0  \n",
       "73            0  \n",
       "74            0  \n",
       "79            0  \n",
       "84            0  \n",
       "85            0  \n",
       "86            0  \n",
       "88            0  \n",
       "92            0  \n",
       "95            0  \n",
       "100           0  \n",
       "107           0  \n",
       "120           0  \n",
       "122           0  \n",
       "...         ...  \n",
       "404155        0  \n",
       "404162        0  \n",
       "404168        0  \n",
       "404170        0  \n",
       "404174        0  \n",
       "404176        0  \n",
       "404183        0  \n",
       "404191        0  \n",
       "404200        0  \n",
       "404206        0  \n",
       "404208        0  \n",
       "404215        0  \n",
       "404221        0  \n",
       "404227        0  \n",
       "404231        0  \n",
       "404241        0  \n",
       "404243        0  \n",
       "404247        0  \n",
       "404249        0  \n",
       "404257        0  \n",
       "404258        0  \n",
       "404259        0  \n",
       "404261        0  \n",
       "404267        0  \n",
       "404273        0  \n",
       "404274        0  \n",
       "404281        0  \n",
       "404282        0  \n",
       "404284        0  \n",
       "404286        0  \n",
       "\n",
       "[96581 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['results']== 0) & (df['is_duplicate'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score\n",
    "cm = confusion_matrix(df['is_duplicate'], df['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[219951,  35076],\n",
       "       [ 96581,  52682]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 67.44\n"
     ]
    }
   ],
   "source": [
    "Total = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1]\n",
    "Accuracy = (cm[0][0] + cm[1][1])/Total\n",
    "print(\"Accuracy %.2f\" %(Accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Acc = accuracy_score(df['is_duplicate'], df['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444534450534\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(df['is_duplicate'], df['results'])\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.352947481961\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(df['is_duplicate'], df['results'])\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame({'question1': df2['question1'],'question2': df2['question2'],'is_duplicate':df['is_duplicate'],'results': df['results']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv(\"submissions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
