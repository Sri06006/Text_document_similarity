{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU, Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_input_file = \"glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_output_file = \"word2vec.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove2word2vec(glove_input_file,word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of loaded word vectors:  400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.array(values[1:],dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "print(\"Len of loaded word vectors: \",len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[\"woman\",\"king\"],negative=['man'],topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Quora Questions dataset and Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quora_duplicate_questions.tsv\",delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['id','qid1','qid2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(lambda s: \" \".join(s1.lower() for s1 in str(s).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['question2'] = df['question2'].apply(lambda s: \" \".join(s1.lower() for s1 in str(s).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].str.replace('[^\\w\\s]','')\n",
    "df['question2'] = df['question2'].str.replace(r'[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "stops = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']\n",
    "# punct = list(string.punctuation)\n",
    "# punct.append(\"''\")\n",
    "# punct.append(\":\")\n",
    "# punct.append(\"...\")\n",
    "# punct.append(\"@\")\n",
    "# punct.append('\"\"')\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False, lemmatization = False):\n",
    "    txt = str(text)\n",
    "    \n",
    "    # Replace apostrophes with standard lexicons\n",
    "    txt = txt.replace(\"isn't\", \"is not\")\n",
    "    txt = txt.replace(\"aren't\", \"are not\")\n",
    "    txt = txt.replace(\"ain't\", \"am not\")\n",
    "    txt = txt.replace(\"won't\", \"will not\")\n",
    "    txt = txt.replace(\"didn't\", \"did not\")\n",
    "    txt = txt.replace(\"shan't\", \"shall not\")\n",
    "    txt = txt.replace(\"haven't\", \"have not\")\n",
    "    txt = txt.replace(\"hadn't\", \"had not\")\n",
    "    txt = txt.replace(\"hasn't\", \"has not\")\n",
    "    txt = txt.replace(\"don't\", \"do not\")\n",
    "    txt = txt.replace(\"wasn't\", \"was not\")\n",
    "    txt = txt.replace(\"weren't\", \"were not\")\n",
    "    txt = txt.replace(\"doesn't\", \"does not\")\n",
    "    txt = txt.replace(\"gotta\",\"got to\")\n",
    "    txt = txt.replace(\"quikly\",\"quickly\")\n",
    "    txt = txt.replace(\"'s\", \" is\")\n",
    "    txt = txt.replace(\"'re\", \" are\")\n",
    "    txt = txt.replace(\"'m\", \" am\")\n",
    "    txt = txt.replace(\"'d\", \" would\")\n",
    "    txt = txt.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # More cleaning\n",
    "    txt = re.sub(r\"review\", \"\", txt)\n",
    "    txt = re.sub(r\"Review\", \"\", txt)\n",
    "    txt = re.sub(r\"TripAdvisor\", \"\", txt)\n",
    "    txt = re.sub(r\"reviews\", \"\", txt)\n",
    "    txt = re.sub(r\"Hotel\", \"\", txt)\n",
    "    txt = re.sub(r\"what's\", \"\", txt)\n",
    "    txt = re.sub(r\"What's\", \"\", txt)\n",
    "    txt = re.sub(r\"\\'s\", \" \", txt)\n",
    "    txt = txt.replace(\"pic\", \"picture\")\n",
    "    txt = re.sub(r\"\\'ve\", \" have \", txt)\n",
    "    txt = re.sub(r\"can't\", \"cannot \", txt)\n",
    "    txt = re.sub(r\"n't\", \" not \", txt)\n",
    "    txt = re.sub(r\"I'm\", \"I am\", txt)\n",
    "    txt = re.sub(r\" m \", \" am \", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are \", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would \", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will \", txt)\n",
    "    txt = re.sub(r\"60k\", \" 60000 \", txt)\n",
    "    txt = re.sub(r\" e g \", \" eg \", txt)\n",
    "    txt = re.sub(r\" b g \", \" bg \", txt)\n",
    "    txt = re.sub(r\"\\0s\", \"0\", txt)\n",
    "    txt = re.sub(r\" 9 11 \", \"911\", txt)\n",
    "    txt = re.sub(r\"e-mail\", \"email\", txt)\n",
    "    txt = re.sub(r\"\\s{2,}\", \" \", txt)\n",
    "    txt = re.sub(r\"quikly\", \"quickly\", txt)\n",
    "    txt = re.sub(r\" usa \", \" America \", txt)\n",
    "    txt = re.sub(r\" USA \", \" America \", txt)\n",
    "    txt = re.sub(r\" u s \", \" America \", txt)\n",
    "    txt = re.sub(r\" uk \", \" England \", txt)\n",
    "    txt = re.sub(r\" UK \", \" England \", txt)\n",
    "    txt = re.sub(r\"india\", \"India\", txt)\n",
    "    txt = re.sub(r\"switzerland\", \"Switzerland\", txt)\n",
    "    txt = re.sub(r\"china\", \"China\", txt)\n",
    "    txt = re.sub(r\"chinese\", \"Chinese\", txt) \n",
    "    txt = re.sub(r\"imrovement\", \"improvement\", txt)\n",
    "    txt = re.sub(r\"intially\", \"initially\", txt)\n",
    "    txt = re.sub(r\"quora\", \"Quora\", txt)\n",
    "    txt = re.sub(r\" dms \", \"direct messages \", txt)  \n",
    "    txt = re.sub(r\"demonitization\", \"demonetization\", txt) \n",
    "    txt = re.sub(r\"actived\", \"active\", txt)\n",
    "    txt = re.sub(r\"kms\", \" kilometers \", txt)\n",
    "    txt = re.sub(r\"KMs\", \" kilometers \", txt)\n",
    "    txt = re.sub(r\" cs \", \" computer science \", txt) \n",
    "    txt = re.sub(r\" upvotes \", \" up votes \", txt)\n",
    "    txt = re.sub(r\" iPhone \", \" phone \", txt)\n",
    "    txt = re.sub(r\"\\0rs \", \" rs \", txt) \n",
    "    txt = re.sub(r\"calender\", \"calendar\", txt)\n",
    "    txt = re.sub(r\"ios\", \"operating system\", txt)\n",
    "    txt = re.sub(r\"gps\", \"GPS\", txt)\n",
    "    txt = re.sub(r\"gst\", \"GST\", txt)\n",
    "    txt = re.sub(r\"programing\", \"programming\", txt)\n",
    "    txt = re.sub(r\"bestfriend\", \"best friend\", txt)\n",
    "    txt = re.sub(r\"dna\", \"DNA\", txt)\n",
    "    txt = re.sub(r\"III\", \"3\", txt) \n",
    "    txt = re.sub(r\"the US\", \"America\", txt)\n",
    "    txt = re.sub(r\"Astrology\", \"astrology\", txt)\n",
    "    txt = re.sub(r\"Method\", \"method\", txt)\n",
    "    txt = re.sub(r\"Find\", \"find\", txt) \n",
    "    txt = re.sub(r\"banglore\", \"Banglore\", txt)\n",
    "    txt = re.sub(r\" J K \", \" JK \", txt)\n",
    "\n",
    "    # Emoji replacement\n",
    "    txt = re.sub(r':\\)',r' Happy ',txt)\n",
    "    txt = re.sub(r':D',r' Happy ',txt)\n",
    "    txt = re.sub(r':P',r' Happy ',txt)\n",
    "    txt = re.sub(r':\\(',r' Sad ',txt)\n",
    "    \n",
    "    # Remove urls and emails\n",
    "    txt = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', txt, flags=re.MULTILINE)\n",
    "    txt = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', txt, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    txt = ''.join([c for c in text if c not in punctuation])\n",
    "#     txt = txt.replace(\".\", \" \")\n",
    "#     txt = txt.replace(\":\", \" \")\n",
    "#     txt = txt.replace(\"!\", \" \")\n",
    "#     txt = txt.replace(\"&\", \" \")\n",
    "#     txt = txt.replace(\"#\", \" \")\n",
    "    \n",
    "    # Remove all symbols\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r' ',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    txt = re.sub(r'[0-9]',r' ',txt)\n",
    "    \n",
    "    # Replace words like sooooooo with so\n",
    "    txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "    \n",
    "    # Split attached words\n",
    "    #txt = \" \".join(re.findall('[A-Z][^A-Z]*', txt))   \n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "#         print (len(txt.split()))\n",
    "#         print (txt)\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(lambda x: cleanData(x, lowercase = False, remove_stops = True, stemming = False, lemmatization = False))\n",
    "df['question2'] = df['question2'].apply(lambda x: cleanData(x,lowercase = False, remove_stops = True, stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step by step guide invest in share market in i...</td>\n",
       "      <td>step by step guide invest in share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase speed my internet connectio...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find remainder when math math divided by</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one dissolve in water quikly sugar salt methan...</td>\n",
       "      <td>fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  step by step guide invest in share market in i...   \n",
       "1                    story kohinoor kohinoor diamond   \n",
       "2  how can i increase speed my internet connectio...   \n",
       "3   why am i mentally very lonely how can i solve it   \n",
       "4  one dissolve in water quikly sugar salt methan...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0          step by step guide invest in share market             0  \n",
       "1  would happen indian government stole kohinoor ...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3           find remainder when math math divided by             0  \n",
       "4                   fish would survive in salt water             0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and creating embedding matrix for question1 and question2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot,text_to_word_sequence,Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = np.hstack([df.question1, df.question2])\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(raw_text)\n",
    "df[\"seq_question1\"] = t.texts_to_sequences(df.question1)\n",
    "df[\"seq_question2\"] = t.texts_to_sequences(df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97906\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(t.word_index) + 1\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max question1 seq 90\n",
      "max question2 seq 181\n"
     ]
    }
   ],
   "source": [
    "max_q1_seq = np.max(df.seq_question1.apply(lambda x: len(x)))\n",
    "max_q2_seq = np.max(df.seq_question2.apply(lambda x: len(x)))\n",
    "print(\"max question1 seq \"+str(max_q1_seq))\n",
    "print(\"max question2 seq \"+str(max_q2_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24bdb53a828>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqRuhoYkqZuhIUnq9v8Al4plQKq88pwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b9c94aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.seq_question1.apply(lambda x: len(x)).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24bc242bfd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMws2/8HAYrINh1Pvj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b9c94a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.seq_question2.apply(lambda x: len(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EMBEDDINGS MAX VALUE\n",
    "#Base on the histograms, we select the next lengths\n",
    "MAX_Q1_SEQ = 40\n",
    "MAX_Q2_SEQ = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97906\n"
     ]
    }
   ],
   "source": [
    "MAX_TEXT = np.max([np.max(df.seq_question1.max()),np.max(df.seq_question2.max())]) + 2\n",
    "print(MAX_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303217, 5)\n",
      "(101073, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(df, random_state=123, train_size=0.75)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'q1': pad_sequences(dataset.seq_question1, maxlen=MAX_Q1_SEQ),\n",
    "        'q2': pad_sequences(dataset.seq_question2, maxlen=MAX_Q2_SEQ)\n",
    "        \n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303217, 40)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['q1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "def get_model():\n",
    "    dropout_r = 0.1\n",
    "    q1 = Input(shape=[X_train[\"q1\"].shape[1]], name=\"q1\")\n",
    "    q2 = Input(shape=[X_train[\"q2\"].shape[1]], name=\"q2\")\n",
    "    emb_q1 = Embedding(MAX_TEXT, 50)(q1)\n",
    "    emb_q2 = Embedding(MAX_TEXT,50)(q2)\n",
    "    rnn_layer1 = GRU(8) (emb_q1)\n",
    "    rnn_layer2 = GRU(16) (emb_q2)\n",
    "    main_l = concatenate([rnn_layer1, rnn_layer2])\n",
    "    main_l = Dropout(dropout_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dropout_r) (Dense(64) (main_l))\n",
    "    output = Dense(1, activation=\"sigmoid\") (main_l)\n",
    "    \n",
    "    model = Model([q1,q2],output)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "q1 (InputLayer)                 (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q2 (InputLayer)                 (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 40, 50)       4895300     q1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 50)       4895300     q2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "gru_11 (GRU)                    (None, 8)            1416        embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_12 (GRU)                    (None, 16)           3216        embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 24)           0           gru_11[0][0]                     \n",
      "                                                                 gru_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          3200        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,806,753\n",
      "Trainable params: 9,806,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303217 samples, validate on 101073 samples\n",
      "Epoch 1/5\n",
      "303217/303217 [==============================] - 151s 499us/step - loss: 0.6595 - acc: 0.6224 - val_loss: 0.6243 - val_acc: 0.6360\n",
      "Epoch 2/5\n",
      "303217/303217 [==============================] - 111s 365us/step - loss: 0.5731 - acc: 0.7066 - val_loss: 0.5617 - val_acc: 0.7295\n",
      "Epoch 3/5\n",
      "303217/303217 [==============================] - 111s 367us/step - loss: 0.5098 - acc: 0.7551 - val_loss: 0.5339 - val_acc: 0.7435\n",
      "Epoch 4/5\n",
      "303217/303217 [==============================] - 114s 375us/step - loss: 0.4667 - acc: 0.7794 - val_loss: 0.5329 - val_acc: 0.7483\n",
      "Epoch 5/5\n",
      "303217/303217 [==============================] - 125s 413us/step - loss: 0.4312 - acc: 0.7990 - val_loss: 0.5373 - val_acc: 0.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24beed7e160>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 20000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, dtrain.is_duplicate, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.is_duplicate)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "val_preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = val_preds.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303217, 5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101073, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_x_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = get_keras_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_preds = model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final_classes = np.argmax(y_final_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['predictions_probs'] = y_final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_score(row):\n",
    "    row['results'] = 1 if row['predictions_probs'] > 0.3 else 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['results'] = df['predictions_probs'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>seq_question1</th>\n",
       "      <th>seq_question2</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_probs</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>motorola company can i hack my charter motorol...</td>\n",
       "      <td>how do i hack motorola dcx free internet</td>\n",
       "      <td>0</td>\n",
       "      <td>[6599, 157, 6, 2, 403, 9, 7673, 54514, 41036]</td>\n",
       "      <td>[1, 4, 2, 403, 6599, 41036, 143, 320]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>method find separation slits using fresnel bip...</td>\n",
       "      <td>are some things technicians can tell durabilit...</td>\n",
       "      <td>0</td>\n",
       "      <td>[907, 69, 4492, 30371, 120, 30372, 54515]</td>\n",
       "      <td>[5, 15, 96, 16769, 6, 232, 16178, 13040, 1740,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>are questions should not ask on quora</td>\n",
       "      <td>question should i ask on quora</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 97, 19, 32, 171, 12, 39]</td>\n",
       "      <td>[145, 19, 2, 171, 12, 39]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>best way make money online</td>\n",
       "      <td>best way ask money online</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 38, 37, 49, 73]</td>\n",
       "      <td>[10, 38, 171, 49, 73]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>whats one thing you would like do better</td>\n",
       "      <td>whats one thing you do despite knowing better</td>\n",
       "      <td>0</td>\n",
       "      <td>[55, 34, 136, 7, 30, 27, 4, 76]</td>\n",
       "      <td>[55, 34, 136, 7, 4, 1876, 1553, 76]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>im yearold how can i improve my skills should ...</td>\n",
       "      <td>i am year old guy how can i become billionaire...</td>\n",
       "      <td>0</td>\n",
       "      <td>[111, 1394, 1, 6, 2, 119, 9, 294, 19, 2, 4, 72...</td>\n",
       "      <td>[2, 56, 87, 130, 253, 1, 6, 2, 72, 2760, 3, 30...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>quickest way increase instagram followers</td>\n",
       "      <td>how can we increase our number instagram follo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3174, 38, 184, 151, 948]</td>\n",
       "      <td>[1, 6, 36, 184, 179, 116, 151, 948]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>how gst affects cas tax officers</td>\n",
       "      <td>why cant i do my homework</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1163, 3851, 15509, 635, 1987]</td>\n",
       "      <td>[8, 191, 2, 4, 9, 6295]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>are best ways learn french</td>\n",
       "      <td>how do i learn french genders</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 10, 103, 54, 955]</td>\n",
       "      <td>[1, 4, 2, 54, 955, 7533]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>why do i always get depressed</td>\n",
       "      <td>why do i always get depressed in evening</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 4, 2, 358, 18, 1655]</td>\n",
       "      <td>[8, 4, 2, 358, 18, 1655, 3, 3775]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.744217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>are types immunity</td>\n",
       "      <td>are different types immunity in our body</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 684, 8757]</td>\n",
       "      <td>[5, 132, 684, 8757, 3, 179, 307]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>how do i prevent breast cancer</td>\n",
       "      <td>breast cancer preventable</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 2, 1053, 3281, 1052]</td>\n",
       "      <td>[3281, 1052, 40408]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>how can i make money internet</td>\n",
       "      <td>are some different ways make money online excl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 2, 37, 49, 320]</td>\n",
       "      <td>[5, 15, 132, 103, 37, 49, 73, 5873, 1630, 96]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>have you ever heard travel hacking</td>\n",
       "      <td>can whatsapp be hacked</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 7, 68, 697, 240, 1275]</td>\n",
       "      <td>[6, 277, 14, 1647]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>usa most powerful country world</td>\n",
       "      <td>why usa most powerful country world</td>\n",
       "      <td>0</td>\n",
       "      <td>[242, 35, 1193, 175, 78]</td>\n",
       "      <td>[8, 242, 35, 1193, 175, 78]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>how do you obtain instant ulcer pain relief</td>\n",
       "      <td>better low back pain heat ice</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 2944, 3589, 13470, 857, 6312]</td>\n",
       "      <td>[76, 645, 174, 857, 1379, 1403]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>are some mindblowing computer tools exist most...</td>\n",
       "      <td>are some mindblowing technologies exist most p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 15, 1246, 169, 896, 295, 35, 25, 83, 51]</td>\n",
       "      <td>[5, 15, 1246, 1791, 295, 35, 25, 83, 51]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>difference between neutral state buffer state</td>\n",
       "      <td>every state usa declared war against each othe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[52, 33, 3828, 301, 7474, 301]</td>\n",
       "      <td>[296, 301, 242, 3265, 140, 309, 345, 77, 30, 182]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>greatest mystery in universe</td>\n",
       "      <td>greatest mystery all time</td>\n",
       "      <td>0</td>\n",
       "      <td>[880, 3438, 3, 396]</td>\n",
       "      <td>[880, 3438, 63, 50]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>our stance against pakistan</td>\n",
       "      <td>stance pakistan in possession weapons mass des...</td>\n",
       "      <td>0</td>\n",
       "      <td>[179, 7596, 309, 271]</td>\n",
       "      <td>[7596, 271, 3, 5920, 2269, 662, 8785, 42, 729,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>how can i stop being afraid working</td>\n",
       "      <td>how do you stop being afraid everything</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 2, 127, 118, 1503, 266]</td>\n",
       "      <td>[1, 4, 7, 127, 118, 1503, 760]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>are stereotypes united kingdom</td>\n",
       "      <td>do americans think united kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 4588, 331, 2932]</td>\n",
       "      <td>[4, 781, 61, 331, 2932]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>are prospering towns in kerala</td>\n",
       "      <td>why are there many christians in kerala</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 41042, 4875, 3, 932]</td>\n",
       "      <td>[8, 5, 31, 62, 2466, 3, 932]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>best way gain confidence</td>\n",
       "      <td>how can i speak with more clarity confidence</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 38, 481, 1562]</td>\n",
       "      <td>[1, 6, 2, 554, 17, 67, 13373, 1562]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>how do i switch from apple music spotify</td>\n",
       "      <td>should i switch from spotify apple music</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 2, 1464, 20, 475, 329, 1153]</td>\n",
       "      <td>[19, 2, 1464, 20, 1153, 475, 329]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>how do i find startup accelerator</td>\n",
       "      <td>how do startup accelerators give you funding</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 2, 69, 454, 9124]</td>\n",
       "      <td>[1, 4, 454, 8647, 207, 7, 1625]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>whats best way start learning robotics</td>\n",
       "      <td>best way start robotics best development board...</td>\n",
       "      <td>0</td>\n",
       "      <td>[55, 10, 38, 75, 181, 3474]</td>\n",
       "      <td>[10, 38, 75, 3474, 10, 378, 893, 2, 6, 75, 266...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>trump supporters how do you feel way hes walki...</td>\n",
       "      <td>do trump supporters now expect president live ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[74, 2066, 1, 4, 7, 88, 38, 2054, 2255, 174, 1...</td>\n",
       "      <td>[4, 74, 2066, 138, 950, 158, 170, 90, 134, 568...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>how do you get book published</td>\n",
       "      <td>are good ways write publish book</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 18, 139, 3186]</td>\n",
       "      <td>[5, 29, 103, 244, 2108, 139]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>why can flash run fast</td>\n",
       "      <td>flash dc character how fast can flash run mile</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 6, 2160, 435, 505]</td>\n",
       "      <td>[2160, 1418, 935, 1, 505, 6, 2160, 435, 6080]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404055</th>\n",
       "      <td>donald trump corrupt</td>\n",
       "      <td>does donald trump think putin corrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>[110, 74, 2630]</td>\n",
       "      <td>[13, 110, 74, 61, 2945, 2630]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404063</th>\n",
       "      <td>speed photon falling in black hole</td>\n",
       "      <td>speed light in black hole</td>\n",
       "      <td>0</td>\n",
       "      <td>[398, 4600, 2254, 3, 137, 1121]</td>\n",
       "      <td>[398, 380, 3, 137, 1121]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404065</th>\n",
       "      <td>epsom salt</td>\n",
       "      <td>does epsom salt bath do you exactly</td>\n",
       "      <td>0</td>\n",
       "      <td>[17120, 1971]</td>\n",
       "      <td>[13, 17120, 1971, 4861, 4, 7, 656]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404076</th>\n",
       "      <td>i am middleclass person in can i contribute india</td>\n",
       "      <td>how does low middle high class live in india</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 56, 10432, 112, 3, 6, 2, 2803, 22]</td>\n",
       "      <td>[1, 13, 645, 1048, 216, 321, 170, 3, 22]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404088</th>\n",
       "      <td>will president obama declare martial law remai...</td>\n",
       "      <td>can president us declare martial law peaceful ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[23, 158, 833, 2824, 2482, 447, 2527, 3, 338, ...</td>\n",
       "      <td>[6, 158, 65, 2824, 2482, 447, 4711, 460]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404110</th>\n",
       "      <td>how do you legally immigrate america from cong...</td>\n",
       "      <td>how can i immigrate us</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 1787, 3784, 362, 20, 12924, 1, 6, 2,...</td>\n",
       "      <td>[1, 6, 2, 3784, 65]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404129</th>\n",
       "      <td>defines outgoing person</td>\n",
       "      <td>how can i get outgoing</td>\n",
       "      <td>0</td>\n",
       "      <td>[7769, 7409, 112]</td>\n",
       "      <td>[1, 6, 2, 18, 7409]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404133</th>\n",
       "      <td>do you feel like time running faster now</td>\n",
       "      <td>why does time feel like it goes faster we get ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 7, 88, 27, 50, 981, 578, 138]</td>\n",
       "      <td>[8, 13, 50, 88, 27, 11, 1479, 578, 36, 18, 1519]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404159</th>\n",
       "      <td>how can i learn more crm</td>\n",
       "      <td>how can we learn more it</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 2, 54, 67, 6104]</td>\n",
       "      <td>[1, 6, 36, 54, 67, 11]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.601851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404160</th>\n",
       "      <td>how can you not be happy</td>\n",
       "      <td>how can i be happy</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 7, 32, 14, 628]</td>\n",
       "      <td>[1, 6, 2, 14, 628]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404161</th>\n",
       "      <td>did hitler think india indian people</td>\n",
       "      <td>hitler would have ruled india</td>\n",
       "      <td>0</td>\n",
       "      <td>[40, 1430, 61, 22, 64, 25]</td>\n",
       "      <td>[1430, 30, 16, 5865, 22]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404164</th>\n",
       "      <td>are best best pictures in academy award history</td>\n",
       "      <td>who has won best actor at academy awards reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 10, 10, 873, 3, 2520, 4690, 285]</td>\n",
       "      <td>[26, 53, 806, 10, 1286, 28, 2520, 5967, 104, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404167</th>\n",
       "      <td>you could ask every human presently alive only...</td>\n",
       "      <td>you could get now instantly completely guarant...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 91, 171, 296, 279, 5980, 1782, 150, 34, 14...</td>\n",
       "      <td>[7, 91, 18, 138, 4160, 1303, 6844, 221, 1143, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404169</th>\n",
       "      <td>how do i make iphone clock show seconds</td>\n",
       "      <td>should i buy second hand iphone s inr</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 2, 37, 173, 3384, 400, 2695]</td>\n",
       "      <td>[19, 2, 105, 734, 999, 173, 211, 752]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404171</th>\n",
       "      <td>how much i can earn blogging</td>\n",
       "      <td>how can one make money starting blog</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 58, 2, 6, 197, 3254]</td>\n",
       "      <td>[1, 6, 34, 37, 49, 915, 678]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404186</th>\n",
       "      <td>best deal website online shopping</td>\n",
       "      <td>best deals site online shopping</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 388, 172, 73, 1509]</td>\n",
       "      <td>[10, 4003, 383, 73, 1509]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404192</th>\n",
       "      <td>drugs have effects are most comparable effects...</td>\n",
       "      <td>are side effects drug glucophage</td>\n",
       "      <td>0</td>\n",
       "      <td>[2199, 16, 297, 5, 35, 7025, 297, 559, 1089]</td>\n",
       "      <td>[5, 569, 297, 489, 97901]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404195</th>\n",
       "      <td>are best mba business schools in world</td>\n",
       "      <td>are top mba colleges in india</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 10, 385, 122, 1035, 3, 78]</td>\n",
       "      <td>[5, 189, 385, 672, 3, 22]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404203</th>\n",
       "      <td>professors from iit guwahati would you love se...</td>\n",
       "      <td>professors from iit delhi would you love see o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[2844, 20, 490, 8336, 30, 7, 89, 141, 12, 39]</td>\n",
       "      <td>[2844, 20, 490, 333, 30, 7, 89, 141, 12, 39]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404204</th>\n",
       "      <td>how do you dye red hair brown</td>\n",
       "      <td>how do you get red hair dye out white tiles</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 3445, 756, 231, 1745]</td>\n",
       "      <td>[1, 4, 7, 18, 756, 231, 3445, 79, 304, 2635]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404217</th>\n",
       "      <td>more shocking moves can be expected by prime m...</td>\n",
       "      <td>after demonetization could be next step needs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[67, 8128, 4563, 6, 14, 1130, 42, 754, 985, 371]</td>\n",
       "      <td>[47, 796, 91, 14, 305, 1243, 1177, 14, 803, 42...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404222</th>\n",
       "      <td>how can i make money in travelling</td>\n",
       "      <td>there any way you can make money from travelling</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 2, 37, 49, 3, 2352]</td>\n",
       "      <td>[31, 43, 38, 7, 6, 37, 49, 20, 2352]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.679841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404225</th>\n",
       "      <td>best site dating experiences</td>\n",
       "      <td>are best asian dating sites</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 383, 855, 1409]</td>\n",
       "      <td>[5, 10, 1231, 855, 477]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404238</th>\n",
       "      <td>how do you know molecule has single double tri...</td>\n",
       "      <td>atom solid liquid gas it none</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 51, 4464, 53, 583, 1295, 4797, 1898]</td>\n",
       "      <td>[2688, 2794, 2011, 1125, 11, 4879]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404239</th>\n",
       "      <td>do foreigner think chinese</td>\n",
       "      <td>do you think chinese people</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 3387, 61, 308]</td>\n",
       "      <td>[4, 7, 61, 308, 25]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404252</th>\n",
       "      <td>best free web hosting php</td>\n",
       "      <td>are best free web hosting services</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 143, 233, 2015, 1304]</td>\n",
       "      <td>[5, 10, 143, 233, 2015, 391]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404260</th>\n",
       "      <td>phone best under</td>\n",
       "      <td>best phone buy below k</td>\n",
       "      <td>0</td>\n",
       "      <td>[102, 10, 164]</td>\n",
       "      <td>[10, 102, 105, 1104, 255]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404262</th>\n",
       "      <td>how do you troubleshoot toshiba laptop</td>\n",
       "      <td>how do i reset toshiba laptop</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 4, 7, 8980, 7787, 228]</td>\n",
       "      <td>[1, 4, 2, 1037, 7787, 228]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404263</th>\n",
       "      <td>how does burning fossil fuels contribute globa...</td>\n",
       "      <td>why does co contribute more global warming wat...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 13, 3587, 5770, 9826, 2803, 1111, 2327]</td>\n",
       "      <td>[8, 13, 2596, 2803, 67, 1111, 2327, 199, 14184]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>do you think removal magsafe connector from ap...</td>\n",
       "      <td>will cpu upgrade apple macbook pro mean</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 7, 61, 2793, 34072, 15934, 20, 3637, 728, ...</td>\n",
       "      <td>[23, 3628, 1728, 475, 728, 668, 82]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38080 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "9       motorola company can i hack my charter motorol...   \n",
       "10      method find separation slits using fresnel bip...   \n",
       "22                  are questions should not ask on quora   \n",
       "28                             best way make money online   \n",
       "30               whats one thing you would like do better   \n",
       "36      im yearold how can i improve my skills should ...   \n",
       "45              quickest way increase instagram followers   \n",
       "54                       how gst affects cas tax officers   \n",
       "59                             are best ways learn french   \n",
       "63                          why do i always get depressed   \n",
       "70                                     are types immunity   \n",
       "76                         how do i prevent breast cancer   \n",
       "78                          how can i make money internet   \n",
       "106                    have you ever heard travel hacking   \n",
       "111                       usa most powerful country world   \n",
       "112           how do you obtain instant ulcer pain relief   \n",
       "118     are some mindblowing computer tools exist most...   \n",
       "121         difference between neutral state buffer state   \n",
       "123                          greatest mystery in universe   \n",
       "140                           our stance against pakistan   \n",
       "151                   how can i stop being afraid working   \n",
       "162                        are stereotypes united kingdom   \n",
       "171                        are prospering towns in kerala   \n",
       "172                              best way gain confidence   \n",
       "174              how do i switch from apple music spotify   \n",
       "183                     how do i find startup accelerator   \n",
       "202                whats best way start learning robotics   \n",
       "234     trump supporters how do you feel way hes walki...   \n",
       "245                         how do you get book published   \n",
       "247                                why can flash run fast   \n",
       "...                                                   ...   \n",
       "404055                               donald trump corrupt   \n",
       "404063                 speed photon falling in black hole   \n",
       "404065                                         epsom salt   \n",
       "404076  i am middleclass person in can i contribute india   \n",
       "404088  will president obama declare martial law remai...   \n",
       "404110  how do you legally immigrate america from cong...   \n",
       "404129                            defines outgoing person   \n",
       "404133           do you feel like time running faster now   \n",
       "404159                           how can i learn more crm   \n",
       "404160                           how can you not be happy   \n",
       "404161               did hitler think india indian people   \n",
       "404164    are best best pictures in academy award history   \n",
       "404167  you could ask every human presently alive only...   \n",
       "404169            how do i make iphone clock show seconds   \n",
       "404171                       how much i can earn blogging   \n",
       "404186                  best deal website online shopping   \n",
       "404192  drugs have effects are most comparable effects...   \n",
       "404195             are best mba business schools in world   \n",
       "404203  professors from iit guwahati would you love se...   \n",
       "404204                      how do you dye red hair brown   \n",
       "404217  more shocking moves can be expected by prime m...   \n",
       "404222                 how can i make money in travelling   \n",
       "404225                       best site dating experiences   \n",
       "404238  how do you know molecule has single double tri...   \n",
       "404239                         do foreigner think chinese   \n",
       "404252                          best free web hosting php   \n",
       "404260                                   phone best under   \n",
       "404262             how do you troubleshoot toshiba laptop   \n",
       "404263  how does burning fossil fuels contribute globa...   \n",
       "404283  do you think removal magsafe connector from ap...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "9                how do i hack motorola dcx free internet             0   \n",
       "10      are some things technicians can tell durabilit...             0   \n",
       "22                         question should i ask on quora             0   \n",
       "28                              best way ask money online             0   \n",
       "30          whats one thing you do despite knowing better             0   \n",
       "36      i am year old guy how can i become billionaire...             0   \n",
       "45      how can we increase our number instagram follo...             0   \n",
       "54                              why cant i do my homework             0   \n",
       "59                          how do i learn french genders             0   \n",
       "63               why do i always get depressed in evening             0   \n",
       "70               are different types immunity in our body             0   \n",
       "76                              breast cancer preventable             0   \n",
       "78      are some different ways make money online excl...             0   \n",
       "106                                can whatsapp be hacked             0   \n",
       "111                   why usa most powerful country world             0   \n",
       "112                         better low back pain heat ice             0   \n",
       "118     are some mindblowing technologies exist most p...             0   \n",
       "121     every state usa declared war against each othe...             0   \n",
       "123                             greatest mystery all time             0   \n",
       "140     stance pakistan in possession weapons mass des...             0   \n",
       "151               how do you stop being afraid everything             0   \n",
       "162                     do americans think united kingdom             0   \n",
       "171               why are there many christians in kerala             0   \n",
       "172          how can i speak with more clarity confidence             0   \n",
       "174              should i switch from spotify apple music             0   \n",
       "183          how do startup accelerators give you funding             0   \n",
       "202     best way start robotics best development board...             0   \n",
       "234     do trump supporters now expect president live ...             0   \n",
       "245                      are good ways write publish book             0   \n",
       "247        flash dc character how fast can flash run mile             0   \n",
       "...                                                   ...           ...   \n",
       "404055              does donald trump think putin corrupt             0   \n",
       "404063                          speed light in black hole             0   \n",
       "404065                does epsom salt bath do you exactly             0   \n",
       "404076       how does low middle high class live in india             0   \n",
       "404088  can president us declare martial law peaceful ...             0   \n",
       "404110                             how can i immigrate us             0   \n",
       "404129                             how can i get outgoing             0   \n",
       "404133  why does time feel like it goes faster we get ...             0   \n",
       "404159                           how can we learn more it             0   \n",
       "404160                                 how can i be happy             0   \n",
       "404161                      hitler would have ruled india             0   \n",
       "404164  who has won best actor at academy awards reall...             0   \n",
       "404167  you could get now instantly completely guarant...             0   \n",
       "404169              should i buy second hand iphone s inr             0   \n",
       "404171               how can one make money starting blog             0   \n",
       "404186                    best deals site online shopping             0   \n",
       "404192                   are side effects drug glucophage             0   \n",
       "404195                      are top mba colleges in india             0   \n",
       "404203  professors from iit delhi would you love see o...             0   \n",
       "404204        how do you get red hair dye out white tiles             0   \n",
       "404217  after demonetization could be next step needs ...             0   \n",
       "404222   there any way you can make money from travelling             0   \n",
       "404225                        are best asian dating sites             0   \n",
       "404238                      atom solid liquid gas it none             0   \n",
       "404239                        do you think chinese people             0   \n",
       "404252                 are best free web hosting services             0   \n",
       "404260                             best phone buy below k             0   \n",
       "404262                      how do i reset toshiba laptop             0   \n",
       "404263  why does co contribute more global warming wat...             0   \n",
       "404283            will cpu upgrade apple macbook pro mean             0   \n",
       "\n",
       "                                            seq_question1  \\\n",
       "9           [6599, 157, 6, 2, 403, 9, 7673, 54514, 41036]   \n",
       "10              [907, 69, 4492, 30371, 120, 30372, 54515]   \n",
       "22                           [5, 97, 19, 32, 171, 12, 39]   \n",
       "28                                   [10, 38, 37, 49, 73]   \n",
       "30                        [55, 34, 136, 7, 30, 27, 4, 76]   \n",
       "36      [111, 1394, 1, 6, 2, 119, 9, 294, 19, 2, 4, 72...   \n",
       "45                              [3174, 38, 184, 151, 948]   \n",
       "54                      [1, 1163, 3851, 15509, 635, 1987]   \n",
       "59                                  [5, 10, 103, 54, 955]   \n",
       "63                               [8, 4, 2, 358, 18, 1655]   \n",
       "70                                         [5, 684, 8757]   \n",
       "76                            [1, 4, 2, 1053, 3281, 1052]   \n",
       "78                                 [1, 6, 2, 37, 49, 320]   \n",
       "106                           [16, 7, 68, 697, 240, 1275]   \n",
       "111                              [242, 35, 1193, 175, 78]   \n",
       "112               [1, 4, 7, 2944, 3589, 13470, 857, 6312]   \n",
       "118          [5, 15, 1246, 169, 896, 295, 35, 25, 83, 51]   \n",
       "121                        [52, 33, 3828, 301, 7474, 301]   \n",
       "123                                   [880, 3438, 3, 396]   \n",
       "140                                 [179, 7596, 309, 271]   \n",
       "151                        [1, 6, 2, 127, 118, 1503, 266]   \n",
       "162                                  [5, 4588, 331, 2932]   \n",
       "171                              [5, 41042, 4875, 3, 932]   \n",
       "172                                   [10, 38, 481, 1562]   \n",
       "174                   [1, 4, 2, 1464, 20, 475, 329, 1153]   \n",
       "183                              [1, 4, 2, 69, 454, 9124]   \n",
       "202                           [55, 10, 38, 75, 181, 3474]   \n",
       "234     [74, 2066, 1, 4, 7, 88, 38, 2054, 2255, 174, 1...   \n",
       "245                              [1, 4, 7, 18, 139, 3186]   \n",
       "247                                [8, 6, 2160, 435, 505]   \n",
       "...                                                   ...   \n",
       "404055                                    [110, 74, 2630]   \n",
       "404063                    [398, 4600, 2254, 3, 137, 1121]   \n",
       "404065                                      [17120, 1971]   \n",
       "404076             [2, 56, 10432, 112, 3, 6, 2, 2803, 22]   \n",
       "404088  [23, 158, 833, 2824, 2482, 447, 2527, 3, 338, ...   \n",
       "404110  [1, 4, 7, 1787, 3784, 362, 20, 12924, 1, 6, 2,...   \n",
       "404129                                  [7769, 7409, 112]   \n",
       "404133                  [4, 7, 88, 27, 50, 981, 578, 138]   \n",
       "404159                            [1, 6, 2, 54, 67, 6104]   \n",
       "404160                             [1, 6, 7, 32, 14, 628]   \n",
       "404161                         [40, 1430, 61, 22, 64, 25]   \n",
       "404164               [5, 10, 10, 873, 3, 2520, 4690, 285]   \n",
       "404167  [7, 91, 171, 296, 279, 5980, 1782, 150, 34, 14...   \n",
       "404169                [1, 4, 2, 37, 173, 3384, 400, 2695]   \n",
       "404171                           [1, 58, 2, 6, 197, 3254]   \n",
       "404186                           [10, 388, 172, 73, 1509]   \n",
       "404192       [2199, 16, 297, 5, 35, 7025, 297, 559, 1089]   \n",
       "404195                     [5, 10, 385, 122, 1035, 3, 78]   \n",
       "404203      [2844, 20, 490, 8336, 30, 7, 89, 141, 12, 39]   \n",
       "404204                    [1, 4, 7, 3445, 756, 231, 1745]   \n",
       "404217   [67, 8128, 4563, 6, 14, 1130, 42, 754, 985, 371]   \n",
       "404222                         [1, 6, 2, 37, 49, 3, 2352]   \n",
       "404225                               [10, 383, 855, 1409]   \n",
       "404238     [1, 4, 7, 51, 4464, 53, 583, 1295, 4797, 1898]   \n",
       "404239                                 [4, 3387, 61, 308]   \n",
       "404252                         [10, 143, 233, 2015, 1304]   \n",
       "404260                                     [102, 10, 164]   \n",
       "404262                         [1, 4, 7, 8980, 7787, 228]   \n",
       "404263        [1, 13, 3587, 5770, 9826, 2803, 1111, 2327]   \n",
       "404283  [4, 7, 61, 2793, 34072, 15934, 20, 3637, 728, ...   \n",
       "\n",
       "                                            seq_question2  predictions  \\\n",
       "9                   [1, 4, 2, 403, 6599, 41036, 143, 320]            0   \n",
       "10      [5, 15, 96, 16769, 6, 232, 16178, 13040, 1740,...            0   \n",
       "22                              [145, 19, 2, 171, 12, 39]            0   \n",
       "28                                  [10, 38, 171, 49, 73]            0   \n",
       "30                    [55, 34, 136, 7, 4, 1876, 1553, 76]            0   \n",
       "36      [2, 56, 87, 130, 253, 1, 6, 2, 72, 2760, 3, 30...            0   \n",
       "45                    [1, 6, 36, 184, 179, 116, 151, 948]            0   \n",
       "54                                [8, 191, 2, 4, 9, 6295]            0   \n",
       "59                               [1, 4, 2, 54, 955, 7533]            0   \n",
       "63                      [8, 4, 2, 358, 18, 1655, 3, 3775]            0   \n",
       "70                       [5, 132, 684, 8757, 3, 179, 307]            0   \n",
       "76                                    [3281, 1052, 40408]            0   \n",
       "78          [5, 15, 132, 103, 37, 49, 73, 5873, 1630, 96]            0   \n",
       "106                                    [6, 277, 14, 1647]            0   \n",
       "111                           [8, 242, 35, 1193, 175, 78]            0   \n",
       "112                       [76, 645, 174, 857, 1379, 1403]            0   \n",
       "118              [5, 15, 1246, 1791, 295, 35, 25, 83, 51]            0   \n",
       "121     [296, 301, 242, 3265, 140, 309, 345, 77, 30, 182]            0   \n",
       "123                                   [880, 3438, 63, 50]            0   \n",
       "140     [7596, 271, 3, 5920, 2269, 662, 8785, 42, 729,...            0   \n",
       "151                        [1, 4, 7, 127, 118, 1503, 760]            0   \n",
       "162                               [4, 781, 61, 331, 2932]            0   \n",
       "171                          [8, 5, 31, 62, 2466, 3, 932]            0   \n",
       "172                   [1, 6, 2, 554, 17, 67, 13373, 1562]            0   \n",
       "174                     [19, 2, 1464, 20, 1153, 475, 329]            0   \n",
       "183                       [1, 4, 454, 8647, 207, 7, 1625]            0   \n",
       "202     [10, 38, 75, 3474, 10, 378, 893, 2, 6, 75, 266...            0   \n",
       "234     [4, 74, 2066, 138, 950, 158, 170, 90, 134, 568...            0   \n",
       "245                          [5, 29, 103, 244, 2108, 139]            0   \n",
       "247         [2160, 1418, 935, 1, 505, 6, 2160, 435, 6080]            0   \n",
       "...                                                   ...          ...   \n",
       "404055                      [13, 110, 74, 61, 2945, 2630]            0   \n",
       "404063                           [398, 380, 3, 137, 1121]            0   \n",
       "404065                 [13, 17120, 1971, 4861, 4, 7, 656]            0   \n",
       "404076           [1, 13, 645, 1048, 216, 321, 170, 3, 22]            0   \n",
       "404088           [6, 158, 65, 2824, 2482, 447, 4711, 460]            0   \n",
       "404110                                [1, 6, 2, 3784, 65]            0   \n",
       "404129                                [1, 6, 2, 18, 7409]            0   \n",
       "404133   [8, 13, 50, 88, 27, 11, 1479, 578, 36, 18, 1519]            0   \n",
       "404159                             [1, 6, 36, 54, 67, 11]            0   \n",
       "404160                                 [1, 6, 2, 14, 628]            0   \n",
       "404161                           [1430, 30, 16, 5865, 22]            0   \n",
       "404164  [26, 53, 806, 10, 1286, 28, 2520, 5967, 104, 1...            0   \n",
       "404167  [7, 91, 18, 138, 4160, 1303, 6844, 221, 1143, ...            0   \n",
       "404169              [19, 2, 105, 734, 999, 173, 211, 752]            0   \n",
       "404171                       [1, 6, 34, 37, 49, 915, 678]            0   \n",
       "404186                          [10, 4003, 383, 73, 1509]            0   \n",
       "404192                          [5, 569, 297, 489, 97901]            0   \n",
       "404195                          [5, 189, 385, 672, 3, 22]            0   \n",
       "404203       [2844, 20, 490, 333, 30, 7, 89, 141, 12, 39]            0   \n",
       "404204       [1, 4, 7, 18, 756, 231, 3445, 79, 304, 2635]            0   \n",
       "404217  [47, 796, 91, 14, 305, 1243, 1177, 14, 803, 42...            0   \n",
       "404222               [31, 43, 38, 7, 6, 37, 49, 20, 2352]            0   \n",
       "404225                            [5, 10, 1231, 855, 477]            0   \n",
       "404238                 [2688, 2794, 2011, 1125, 11, 4879]            0   \n",
       "404239                                [4, 7, 61, 308, 25]            0   \n",
       "404252                       [5, 10, 143, 233, 2015, 391]            0   \n",
       "404260                          [10, 102, 105, 1104, 255]            0   \n",
       "404262                         [1, 4, 2, 1037, 7787, 228]            0   \n",
       "404263    [8, 13, 2596, 2803, 67, 1111, 2327, 199, 14184]            0   \n",
       "404283                [23, 3628, 1728, 475, 728, 668, 82]            0   \n",
       "\n",
       "        predictions_probs  results  \n",
       "9                0.872880        1  \n",
       "10               0.685111        1  \n",
       "22               0.661586        1  \n",
       "28               0.915489        1  \n",
       "30               0.847040        1  \n",
       "36               0.696536        1  \n",
       "45               0.894277        1  \n",
       "54               0.635375        1  \n",
       "59               0.763403        1  \n",
       "63               0.744217        1  \n",
       "70               0.590225        1  \n",
       "76               0.864138        1  \n",
       "78               0.764255        1  \n",
       "106              0.767732        1  \n",
       "111              0.682922        1  \n",
       "112              0.643836        1  \n",
       "118              0.585848        1  \n",
       "121              0.528763        1  \n",
       "123              0.763945        1  \n",
       "140              0.795198        1  \n",
       "151              0.556464        1  \n",
       "162              0.514626        1  \n",
       "171              0.577168        1  \n",
       "172              0.591761        1  \n",
       "174              0.531235        1  \n",
       "183              0.769049        1  \n",
       "202              0.853547        1  \n",
       "234              0.670789        1  \n",
       "245              0.696566        1  \n",
       "247              0.685061        1  \n",
       "...                   ...      ...  \n",
       "404055           0.827126        1  \n",
       "404063           0.565513        1  \n",
       "404065           0.691016        1  \n",
       "404076           0.529843        1  \n",
       "404088           0.713184        1  \n",
       "404110           0.527725        1  \n",
       "404129           0.585655        1  \n",
       "404133           0.727495        1  \n",
       "404159           0.601851        1  \n",
       "404160           0.543230        1  \n",
       "404161           0.638111        1  \n",
       "404164           0.580262        1  \n",
       "404167           0.625548        1  \n",
       "404169           0.731046        1  \n",
       "404171           0.592174        1  \n",
       "404186           0.726692        1  \n",
       "404192           0.582098        1  \n",
       "404195           0.652097        1  \n",
       "404203           0.640307        1  \n",
       "404204           0.571034        1  \n",
       "404217           0.758059        1  \n",
       "404222           0.679841        1  \n",
       "404225           0.570755        1  \n",
       "404238           0.549426        1  \n",
       "404239           0.659718        1  \n",
       "404252           0.582592        1  \n",
       "404260           0.574895        1  \n",
       "404262           0.625719        1  \n",
       "404263           0.696759        1  \n",
       "404283           0.536970        1  \n",
       "\n",
       "[38080 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['results']== 1) & (df['is_duplicate'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score\n",
    "cm = confusion_matrix(df['is_duplicate'], df['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[216947,  38080],\n",
       "       [ 43992, 105271]], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 79.70\n"
     ]
    }
   ],
   "source": [
    "Total = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1]\n",
    "Accuracy = (cm[0][0] + cm[1][1])/Total\n",
    "print(\"Accuracy %.2f\" %(Accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Acc = accuracy_score(df['is_duplicate'], df['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719521280595\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(df['is_duplicate'], df['results'])\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705271902615\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(df['is_duplicate'], df['results'])\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
